{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The decision tree with Scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def convert_from_scikit_learn_to_dic_ite(node_index,is_leaves, children_left,children_right,feature,threshold,value,labels,C):\n",
    "        \n",
    "        a = is_leaves[0]\n",
    "        b = feature[0]\n",
    "        c = threshold[0]\n",
    "        if (a):\n",
    "            d = value[0]  #datapoints of each class in the node\n",
    "            d2 = np.squeeze(d/np.sum(d))\n",
    "            d3 = np.zeros(C)\n",
    "            d3[labels] = d2\n",
    "            e = labels[np.argmax(d2)]\n",
    "            return {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True,\n",
    "            'prediction': e,\n",
    "            'labels_distribution':d3}\n",
    "    \n",
    "        else:\n",
    "            left = children_left[0]-node_index[0]\n",
    "            if(left==-1):\n",
    "                left_tree = None\n",
    "            else:\n",
    "                left_tree = convert_from_scikit_learn_to_dic_ite(node_index[left:],is_leaves[left:], children_left[left:],children_right[left:],feature[left:],threshold[left:],value[left:],labels,C)\n",
    "            right = children_right[0]-node_index[0]\n",
    "            if(right==-1):\n",
    "                right_tree = None\n",
    "            else:\n",
    "                right_tree = convert_from_scikit_learn_to_dic_ite(node_index[right:],is_leaves[right:], children_left[right:],children_right[right:],feature[right:],threshold[right:],value[right:],labels,C)\n",
    "            return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': b,\n",
    "            'threshold'        : c,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree,\n",
    "            'labels_distribution': None}\n",
    "\n",
    "\n",
    "def convert_from_scikit_learn_to_dic(tree,labels,C):\n",
    "    # C is the size of the whole labels\n",
    "    # labels are the labels that are used in the this tree\n",
    "\n",
    "    n_nodes = tree.tree_.node_count\n",
    "    children_left = tree.tree_.children_left\n",
    "    children_right = tree.tree_.children_right\n",
    "    feature = tree.tree_.feature\n",
    "    threshold = tree.tree_.threshold\n",
    "    node_index = np.array(range(0,n_nodes))\n",
    "    Val = tree.tree_.value   #datapoints in node\n",
    "\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "\n",
    "    # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "    \n",
    "    return convert_from_scikit_learn_to_dic_ite(node_index,is_leaves, children_left,children_right,feature,threshold,Val,labels,C)\n",
    "\n",
    "def classify(tree, x):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        return tree['labels_distribution'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        val_split_feature = x[tree['splitting_feature']]\n",
    "        if val_split_feature < tree['threshold']:\n",
    "            return classify(tree['left'], x)\n",
    "        else:\n",
    "            return classify(tree['right'],x)\n",
    "\n",
    "def evaluate_classification_error_tree(tree, X, y):\n",
    "    if type(y) == np.uint8:# or X.shape[0] < 2:   #if we have only 1 datapoint in X\n",
    "        P = classify(tree,X)\n",
    "        prediction = np.argmax(P)\n",
    "        error = int(prediction != y)\n",
    "    else:\n",
    "        # Apply the classify(tree, x) to each row in your data\n",
    "\n",
    "        P = map(lambda x: classify(tree,x), X)\n",
    "        P = np.asarray(P)\n",
    "        prediction = np.argmax(P,axis=1)\n",
    "        # Once you've made the predictions, calculate the classification error and return it\n",
    "        mistakes = sum(prediction != y)\n",
    "        error = mistakes/len(y)\n",
    "        \n",
    "    return error\n",
    "\n",
    "def intermediate_node_num_mistakes(labels_in_node):\n",
    "    \n",
    "    # Corner case: If labels_in_node is empty, return 0\n",
    "    if len(labels_in_node) == 0:\n",
    "        return 0\n",
    "    \n",
    "    C,unique_counts = np.unique(labels_in_node,return_counts=True) #the id of classes and number of each\n",
    "    \n",
    "    return (len(labels_in_node) - unique_counts[np.argmax(unique_counts)])\n",
    "\n",
    "def datapath(tree, x, branch = 1):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        return branch \n",
    "    else:\n",
    "        # split on feature.\n",
    "        split_feature = tree['splitting_feature']\n",
    "        split_threshold = tree['threshold']\n",
    "\n",
    "        if x[split_feature] < split_threshold:\n",
    "            return datapath(tree['left'], x, 2*branch)\n",
    "        else:\n",
    "            return datapath(tree['right'],x, 2*branch+1)\n",
    "\n",
    "def expansion_reduction_SKL(tree,XT1,yT1,XT2,yT2,C):\n",
    "\n",
    "    \n",
    "    #finding the leaf where each target datapoint ends up\n",
    "    leavesData1 = map(lambda x: datapath(tree,x), XT1)\n",
    "    leavesData2 = map(lambda x: datapath(tree,x), XT2)\n",
    "            \n",
    "    Uleaves1 = np.unique(leavesData1)  #the path to each leaf followed by data1\n",
    "    Uleaves2 = np.unique(leavesData2)  #the path to each leaf followed by data2\n",
    "    Uleaves = list(set(Uleaves1) & set(Uleaves2)) #leaves reached by both data1 and data2\n",
    "            \n",
    "    #expanding each leaf on the 1st bootstrap replica of target data\n",
    "    for i in Uleaves:\n",
    "        \n",
    "        ind_data1 = leavesData1==i #indices of datapoints for each leaf\n",
    "        ind_data2 = leavesData2==i\n",
    "        \n",
    "        if len(ind_data1) < 2:  #do not expand if there is only 1 datapoint\n",
    "            continue\n",
    "            \n",
    "        estimator = DecisionTreeClassifier(max_features='sqrt') #use sqrt the number of feat.\n",
    "        estimator = estimator.fit(XT1[ind_data1,:],yT1[ind_data1]) \n",
    "        #print 'Nclasses ExpTree = %s'%np.unique(yT1[ind_data1]) #%estimator.tree_.n_classes\n",
    "        \n",
    "        Exp_tree = convert_from_scikit_learn_to_dic(estimator,np.unique(yT1[ind_data1]),C)\n",
    "\n",
    "        #Is this a good expansion?: computes classification error at each leaf for Data T2\n",
    "        Err_leavesT2 = intermediate_node_num_mistakes(yT2[ind_data2])/len(yT2[ind_data2])\n",
    "\n",
    "        #error at the current subtree on Data T2\n",
    "        Err_subtreeT2 = evaluate_classification_error_tree(Exp_tree, XT2[ind_data2,:], yT2[ind_data2])\n",
    "        #comparing the error of the subtree with that at the leaf node of the original tree\n",
    "        if Err_subtreeT2 < Err_leavesT2:\n",
    "            tree = mergetrees(tree,i,Exp_tree)\n",
    "            #print 'merging successful!'\n",
    "            #print 'subtree nodes = %s'%count_nodes(Exp_tree)\n",
    "\n",
    "        #else:\n",
    "            #print 'no merging: discard subtree'\n",
    "    \n",
    "    return tree\n",
    "\n",
    "\n",
    "\n",
    "def mergetrees(tree1,leafnr,tree2):\n",
    "    leafnrbin = bin(leafnr)[3:]  #path is from the 4th element of the binary on: 0 = go left, 1 = go right\n",
    "    path = ''\n",
    "    for i in range(len(leafnrbin)):\n",
    "        if leafnrbin[i] == '0':\n",
    "            path=path+str(\"['left']\")\n",
    "        else:\n",
    "            path=path+str(\"['right']\") \n",
    "    # print(path)\n",
    "    exec ('tree1'+path+\"['prediction']\"+'=None')\n",
    "    exec ('tree1'+path+\"['is_leaf']\"+'=False')\n",
    "    exec ('tree1'+path+\"['left']\"+\"=tree2['left']\")\n",
    "    exec ('tree1'+path+\"['right']\"+\"=tree2['right']\")\n",
    "    exec ('tree1'+path+\"['splitting_feature']\"+\"=tree2['splitting_feature']\")\n",
    "    exec ('tree1'+path+\"['threshold']\"+\"=tree2['threshold']\")\n",
    "    exec ('del(tree1'+path+\"['labels_distribution'])\")\n",
    "    return tree1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  STRUCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import log\n",
    "\n",
    "def kl(p, q): # Kullback-libler divegence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    return np.sum(np.where(p != 0,(p-q) * np.log10(p / q), 0))\n",
    "def jsd(p,q): # Symmetric Kullback-libler divegence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    m = (p+q)/2\n",
    "    return (kl(p,m)+kl(m,q))/2\n",
    "\n",
    "def find_left_right(S,feature,labels,C,threshold): # finding the left and right division\n",
    "    left = S[:,feature]<threshold\n",
    "    labels_left = labels[left]\n",
    "    right = S[:,feature]>threshold\n",
    "    labels_right = labels[right]\n",
    "    QL = np.bincount(labels_left)\n",
    "    #if(len(QL)<C)\n",
    "    #b.append(np.zeros(C-len(a))) \n",
    "    labels_right = labels[left]\n",
    "    QR = np.bincount(labels_right)\n",
    "    return QL,QF\n",
    "\n",
    "def dg(Sleft,lenleft,Sright,lenright,f,t,QL,QR): # DG function as in the paper, S is the datast with the features\n",
    "    return 1-(lenleft/(lenleft+lenright))*jsd(Sleft,QL)-(lenright/(lenleft+lenright))*jsd(Sright,QR)\n",
    "    \n",
    "def threshold_selection(S,f,QL,QR,C): # finding the best threshold\n",
    "    Val = []\n",
    "    for i in range([200]):\n",
    "        Sleft, Sright = find_left_right(S,f,labels,C,i-100)\n",
    "        Val[i] = dg(Sleft,lenleft,Sright,lenright,f,t,QL,QR)\n",
    "    return min(Val)\n",
    "    \n",
    "def STRUC(Xsource,ysource,Xtarget,ytarget,C):\n",
    "    estimator = DecisionTreeClassifier(max_features='sqrt',max_leaf_nodes=100,random_state=0)\n",
    "    estimator = estimator.fit(Xsource, ysource)\n",
    "    P = []\n",
    "    for i in range(estimator.tree_.capacity):\n",
    "        QL = estimator.tree_.children_left[i]\n",
    "        QR = estimator.tree_.children_right[i]\n",
    "        f = estimator.tree_.feature[1]\n",
    "        P[i] = threshold_selection(Xtarget,f,QL,QR,C)\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a= np.bincount([1,1,3,5])\n",
    "print a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(10000, 784)\n",
      "(27500, 784)\n",
      "(27500, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "from __future__ import division\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"../MNIST_data/\", one_hot=False)\n",
    "Xtrain = mnist.train.images\n",
    "Xtest = mnist.test.images\n",
    "ytrain = mnist.train.labels\n",
    "ytest = mnist.test.labels\n",
    "Xsource, Xtarget, ysource, ytarget = train_test_split(Xtrain, ytrain, test_size=0.5)\n",
    "print Xtrain.shape\n",
    "print Xtest.shape\n",
    "print Xsource.shape\n",
    "print Xtarget.shape\n",
    "XT1,XT2,yT1,yT2 = train_test_split(Xtarget,ytarget,test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator = DecisionTreeClassifier(max_features='sqrt',max_leaf_nodes=100,random_state=0)\n",
    "estimator = estimator.fit(Xsource, ysource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.tree_.feature[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
