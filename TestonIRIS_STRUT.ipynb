{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.data\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.target\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRUT fcns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from math import log\n",
    "\n",
    "def convert_from_scikit_learn_to_dic_ite(node_index,is_leaves, children_left,children_right,feature,threshold,value,labels,C):\n",
    "        \n",
    "        a = is_leaves[0]\n",
    "        b = feature[0]\n",
    "        c = threshold[0]\n",
    "        if (a):\n",
    "            d = value[0]  #datapoints of each class in the node\n",
    "            d2 = np.squeeze(d/np.sum(d))\n",
    "            d3 = np.zeros(C)\n",
    "            d3[labels] = d2\n",
    "            e = labels[np.argmax(d2)]\n",
    "            return {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True,\n",
    "            'prediction': e,\n",
    "            'labels_distribution':d3}\n",
    "    \n",
    "        else:\n",
    "            left = children_left[0]-node_index[0]\n",
    "            if(left==-1):\n",
    "                left_tree = None\n",
    "            else:\n",
    "                left = int(left)\n",
    "                left_tree = convert_from_scikit_learn_to_dic_ite(node_index[left:],is_leaves[left:], children_left[left:],children_right[left:],feature[left:],threshold[left:],value[left:],labels,C)\n",
    "            right = children_right[0]-node_index[0]\n",
    "            if(right==-1):\n",
    "                right_tree = None\n",
    "            else:\n",
    "                right = int(right)\n",
    "                right_tree = convert_from_scikit_learn_to_dic_ite(node_index[right:],is_leaves[right:], children_left[right:],children_right[right:],feature[right:],threshold[right:],value[right:],labels,C)\n",
    "            return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': b,\n",
    "            'threshold'        : c,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree,\n",
    "            'labels_distribution': None}\n",
    "\n",
    "\n",
    "def convert_from_scikit_learn_to_dic_STRUT(tree,threshold,C,Q,target_lf,target_lr,feature):\n",
    "    # C is the size of the whole labels\n",
    "    # labels are the labels that are used in the this tree\n",
    "    labels = range(0,C,1)\n",
    "    #n_nodes = tree.tree_.node_count\n",
    "    n_nodes = target_lr.shape[0]\n",
    "    children_left = target_lf\n",
    "    children_right = target_lr\n",
    "    #feature = tree.tree_.feature\n",
    "    node_index = np.array(range(0,n_nodes))\n",
    "    Val = Q   #datapoints in node\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "    # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "    \n",
    "    return convert_from_scikit_learn_to_dic_ite(node_index,is_leaves, children_left,children_right,feature,threshold,Val,labels,C)\n",
    "\n",
    "def TransferToSKLsequence(ch_left,ch_right,subset):\n",
    "    new_left = np.zeros(len(subset))\n",
    "    new_right = np.zeros(len(subset))\n",
    "    for i in range(len(subset)):\n",
    "        (I,) = np.where(subset == ch_left[subset[i]])\n",
    "        if len(I)==0:\n",
    "            new_left[i] = -1\n",
    "        else:\n",
    "            \n",
    "            new_left[i] = I\n",
    "            \n",
    "        (I,) = np.where(subset == ch_right[subset[i]])\n",
    "        if len(I)==0:\n",
    "            new_right[i] = -1\n",
    "        else:\n",
    "            new_right[i] = I\n",
    "    return (new_left,new_right)\n",
    "\n",
    "def kl (p,q): # Kullback-libler divegence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)+.0001\n",
    "    return np.sum(np.where(p != 0,p * np.log10((p / q)), 0))\n",
    "\n",
    "def jsd(p,q): # Symmetric Kullback-libler divergence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    m = (p+q)/2\n",
    "    return (kl(p,m)+kl(m,q))/2\n",
    "\n",
    "def infogain(yleft,len_left,yright,len_right):\n",
    "    yparent = (yleft+yright)/2\n",
    "    N = len_left+len_right\n",
    "    #compute information gain\n",
    "    I = entropy(yparent) -( (len_left/N)*entropy(yleft) + (len_right/N)*entropy(yright) )   \n",
    "    return I\n",
    "\n",
    "#entropy for multiple classes\n",
    "def entropy(y):\n",
    "    y1 = y[y!=0]\n",
    "    H = -(y1*np.log10(y1)).sum()\n",
    "    return H \n",
    "\n",
    "def partition(Xtarget,ytarget,index_of_data,feature,C,threshold): # divide the data to the left and rightbased on the threshold\n",
    "    left = index_of_data[Xtarget[index_of_data,feature]<threshold]\n",
    "    if(len(left)==0):\n",
    "        left = index_of_data[Xtarget[index_of_data,feature]<=threshold]\n",
    "    labels_left = ytarget[left]\n",
    "    qL = np.bincount(labels_left)\n",
    "    right = index_of_data[Xtarget[index_of_data,feature]>=threshold]\n",
    "    labels_right = ytarget[right]\n",
    "    qR = np.bincount(labels_right)\n",
    "    qR = np.append(qR,np.zeros(np.max([C-qR.shape[0],0])))\n",
    "    qL = np.append(qL,np.zeros(np.max([C-qL.shape[0],0]))) \n",
    "    qL = qL/qL.sum()\n",
    "    qR = qR/qR.sum()\n",
    "    return [qL,left,qR,right]\n",
    "\n",
    "def dg(Sleft,lenleft,Sright,lenright,QL,QR): # DG function as in the paper    \n",
    "    return 1-(lenleft/(lenleft+lenright))*jsd(Sleft,QL)-(lenright/(lenleft+lenright))*jsd(Sright,QR)\n",
    "    \n",
    "def threshold_selection(X,y,S,f,QL,QR,C,verbos): # finding the best threshold\n",
    "    fvals = np.sort(X[S,f])\n",
    "    num_data_points = len(fvals)\n",
    "    N = 10\n",
    "    Val  = np.array([])\n",
    "    #Val_swap  = np.array([])\n",
    "    Val_infogain = np.array([])\n",
    "    if num_data_points > N-1: \n",
    "        I = range(0,num_data_points,np.floor(num_data_points/N).astype(int))\n",
    "        fvals = fvals[I[1:-1]]\n",
    "    for i in fvals: #looping through the thresholds\n",
    "        [Sleft, left, Sright, right] = partition(X,y,S,f,C,i) #find splits based on threshold\n",
    "        \n",
    "        #fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex='col', sharey='row')\n",
    "        #ax1.plot(QL)\n",
    "        #ax1.set_title('QL')\n",
    "        #ax2.plot(Sleft, color='r')\n",
    "        #ax2.set_title('QprimeL')\n",
    "        #ax3.plot(QR)\n",
    "        #ax3.set_title('QR')\n",
    "        #ax4.plot(Sright, color='r')\n",
    "        #ax4.set_title('QprimeR')\n",
    "        Val = np.append(Val,dg(Sleft,len(left),Sright,len(right),QL,QR)) # Here we compute DG between the source dist and target\n",
    "        #print 'DG = %s' %Val[-1]\n",
    "        #print 'QL=%s, QR=%s, Sleft=%s, Sright=%s' %(QL,QR,Sleft,Sright)\n",
    "        Val_infogain = np.append(Val_infogain,infogain(Sleft,len(left),Sright,len(right))) #Compute IG\n",
    "        #Val_swap = np.append(Val_swap,dg(Sleft,len(left),Sright,len(right),QR,QL)) # this is the divergence measure for each threshold split  \n",
    "    if(verbos):\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex='col', sharey='row')\n",
    "    #ax1.plot(Val)\n",
    "    #ax1.set_title('DG')\n",
    "    #ax2.plot(Val_infogain)\n",
    "    #ax2.set_title('infogain')\n",
    "        ax1.plot(fvals,Val,'r')\n",
    "        ax1.hold(True)\n",
    "        ax1.plot(fvals,Val_infogain)\n",
    "        ax1.hold(False)\n",
    "        ax1.set_title('DG and Infogain')\n",
    "    #plt.show()\n",
    "    Val[np.isnan(Val)] = min(Val[~np.isnan(Val)])\n",
    "    Val_infogain[np.isnan(Val_infogain)] = min(Val_infogain[~np.isnan(Val_infogain)])\n",
    "    #Val_swap[np.isnan(Val_swap)] = min(Val_swap[~np.isnan(Val_swap)])\n",
    "    th = fvals[np.argmax(Val)] #Maximizing threshold for DG\n",
    "    th_infogain = fvals[np.argmax(Val_infogain)]\n",
    "    if(len(S)<50):\n",
    "        [ql, left, qr, right] = partition(X,y,S,f,C,th_infogain)\n",
    "    else:\n",
    "        [ql, left, qr, right] = partition(X,y,S,f,C,th)\n",
    "    if(verbos):\n",
    "        ax2.plot(ql)\n",
    "        ax2.hold(True)\n",
    "        ax2.plot(qr)\n",
    "        ax2.hold(False)\n",
    "        ax2.set_title('Dist Target Data')\n",
    "\n",
    "        ax3.plot(QL)\n",
    "        ax3.hold(True)\n",
    "        ax3.plot(QR)\n",
    "        ax3.hold(False)\n",
    "        ax3.set_title('Dist Source Data')\n",
    "    #print Val\n",
    "    return [th, ql, qr, left, right]\n",
    "\n",
    "def classify(tree, x):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        return tree['labels_distribution'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        val_split_feature = x[tree['splitting_feature']]\n",
    "        if val_split_feature < tree['threshold']:\n",
    "            return classify(tree['left'], x)\n",
    "        else:\n",
    "            return classify(tree['right'],x)\n",
    "\n",
    "def forest_posterior(RF,x):\n",
    "\n",
    "    T = len(RF)  #the number of trees \n",
    "\n",
    "    #infer the number of classes\n",
    "    P0 = classify(RF[0],x)\n",
    "    C = len(P0)\n",
    "    \n",
    "    Pt = np.zeros((T,C)) #matrix of posteriors from each tree (T x Nclasses)\n",
    "    Pt[0,:] = P0\n",
    "    for t in range(len(RF))[1:]:\n",
    "        Pt[t,:] = classify(RF[t],x) \n",
    "    return Pt\n",
    "\n",
    "#classify input based on majority voting of each tree prediction\n",
    "def forest_classify_majority(RF,x):\n",
    "        Pt = forest_posterior(RF,x)\n",
    "        Yt = np.argmax(Pt,axis=1)         \n",
    "        C,unique_counts = np.unique(Yt,return_counts=True) #the id of classes and number of each\n",
    "        return C[np.argmax(unique_counts)]   \n",
    "    \n",
    "#classify input by averaging posteriors \n",
    "def forest_classify_ensemble(RF,x):\n",
    "    Pt = forest_posterior(RF,x)\n",
    "    Pforest = Pt.mean(axis=0)\n",
    "    ypred = np.argmax(Pt.mean(axis=0))\n",
    "    return ypred\n",
    "\n",
    "def evaluate_classification_error(RF, X, y, method = None):  \n",
    "    # Apply the forest_classify(RF, x) to each row in your data\n",
    "    if method == None:\n",
    "        ypred = map(lambda x: forest_classify_ensemble(RF,x), X)\n",
    "        # Once you've made the predictions, calculate the classification error and return it\n",
    "        mistakes = sum(ypred != y)\n",
    "        error = mistakes/len(y)\n",
    "    return error\n",
    "\n",
    "def value_for_all(estimator,N):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    ch_left = estimator.tree_.children_left\n",
    "    ch_right = estimator.tree_.children_right\n",
    "    (cl,) = np.where(ch_left!=-1)\n",
    "    (cr,) = np.where(ch_right!=-1)\n",
    "    cap = estimator.tree_.capacity\n",
    "    dis_node = np.zeros((cap,estimator.tree_.n_classes))\n",
    "    A = np.zeros([cap,cap])\n",
    "    D = A\n",
    "    A = csr_matrix(A)\n",
    "    A[cl,ch_left[cl]] = 1\n",
    "    A[cr,ch_right[cr]] = 1\n",
    "    B = A\n",
    "    C = B\n",
    "    while(C.sum()!=0):\n",
    "        C = A*C\n",
    "        B = B + C\n",
    "    I,J = B.nonzero()\n",
    "    D[I,J] = 1\n",
    "    (I,) = np.where(ch_left==-1)\n",
    "    dis_node[I,:] = np.squeeze(estimator.tree_.value[I])\n",
    "    for i in I:\n",
    "        dis_node[i,:] = dis_node[i,:]/dis_node[i,:].sum()\n",
    "    (remain1,) = np.where(ch_left!=-1)\n",
    "    for i in remain1:\n",
    "        (I,) = np.where(D[i,:]==1)\n",
    "        dis_node[i,:] = np.sum(np.squeeze(estimator.tree_.value[I]),axis = 0)\n",
    "        dis_node[i,:] = dis_node[i,:]/dis_node[i,:].sum()\n",
    "    Dis_node = np.zeros((cap,N))\n",
    "    Dis_node[:,estimator.classes_.astype(int)] = dis_node\n",
    "    return Dis_node\n",
    "    \n",
    "def STRUCT(Xsource,ysource,Xtarget,ytarget,n_trees,C,verbos = False):\n",
    "    # Assumption: ysource has all the labels of the problem \n",
    "    #estimator = DecisionTreeClassifier(max_features='sqrt',random_state=0,max_depth=2)\n",
    "    Estimator = RandomForestClassifier(max_features='sqrt',random_state=0,n_estimators=n_trees)\n",
    "    Estimator = Estimator.fit(Xsource, ysource)\n",
    "    RF = []\n",
    "    for rf in range(Estimator.n_estimators):   #can we change it to a parfor loop or map?\n",
    "        estimator = Estimator.estimators_[rf]\n",
    "        dis_node = value_for_all(estimator,C)\n",
    "        P = list(np.zeros(estimator.tree_.capacity))\n",
    "        P[0] = range(len(ytarget))\n",
    "        Q = list(np.zeros(estimator.tree_.capacity))\n",
    "        Q[0] = dis_node[0,:]\n",
    "        thresh = np.zeros(estimator.tree_.capacity)\n",
    "        remain = [0]\n",
    "        subset = []\n",
    "        while(len(remain)!=0):\n",
    "            i = remain[0]\n",
    "            LF = estimator.tree_.children_left\n",
    "            LR = estimator.tree_.children_right\n",
    "            index_left = LF[i]\n",
    "            index_right = LR[i]\n",
    "            if(index_left!=-1):\n",
    "                QL = dis_node[index_left,:]\n",
    "                QR = dis_node[index_right,:]\n",
    "                f = estimator.tree_.feature[i]\n",
    "                [th, ql, qr, left, right] = threshold_selection(Xtarget,ytarget,np.array(P[i]),f,QL,QR,C,verbos) \n",
    "                thresh[i] = th\n",
    "                P[index_left] = left\n",
    "                P[index_right] = right\n",
    "                Q[index_left] = ql\n",
    "                Q[index_right] = qr\n",
    "                if(len(left)!=0):\n",
    "                    remain = np.append(remain,index_left)\n",
    "                if(len(right)!=0):\n",
    "                    remain = np.append(remain,index_right)\n",
    "                if(len(left)>0 and len(right)>0):\n",
    "                    subset.append(i)\n",
    "            remain = remain[1:]\n",
    "        lf =  LF[subset]\n",
    "        lr =  LR[subset]\n",
    "        subset = np.append(subset,lf)\n",
    "        subset = np.append(subset,lr)\n",
    "        subset = np.unique(np.sort(subset))\n",
    "        subset = np.array(subset)\n",
    "        (target_lf,target_lr) = TransferToSKLsequence(np.array(LF),np.array(LR),subset)\n",
    "        ST = convert_from_scikit_learn_to_dic_STRUT(estimator,thresh,C,Q,target_lf,target_lr,estimator.tree_.feature[subset])\n",
    "        RF.append(ST)\n",
    "    return RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121  27  13  48  53  57  87  73  81   1  30  65  40  74  54   6  51   0\n",
      "  45  24 128 111  67  64  61  82  97  36  70 122 120  35  29 124  98  11\n",
      "  26   8 106  95 123  47  17 146 145 139  94 144 114  55  59  66 103  31\n",
      "  52  71  86 141 138 133  15  93  28 105 115 109  85 147  20  23  33  84\n",
      "  79 126  99  63  38 140  43 135 107   7  77 113 148  49   5 132   4  75\n",
      "  88  50  60  42  22  25  89  37  18 142 143 137  10  46  96 118 100  44\n",
      " 131  62  92  41  76  72 117 119  69 127  16  58 101  83   3  19 134 102\n",
      " 125 116 104 149  78  14 108  12   9  68  80 129  39  91  34 110  90 130\n",
      "   2 112  32 136  21  56]\n"
     ]
    }
   ],
   "source": [
    "ind = np.arange(len(y))\n",
    "np.random.shuffle(ind)\n",
    "print ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xsource = X[ind[0:100],:]\n",
    "ysource = y[ind[0:100]]\n",
    "Xtarget = X[ind[100:],:]\n",
    "ytarget = y[ind[100:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:251: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:93: RuntimeWarning: divide by zero encountered in log10\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:93: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:62: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:64: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:65: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:66: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:68: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82718706131\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "STRUCT(Xsource,ysource,Xtarget,ytarget,n_trees=50,C=3,verbos = False)\n",
    "t1 = time()\n",
    "print t1-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:251: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:93: RuntimeWarning: divide by zero encountered in log10\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:93: RuntimeWarning: invalid value encountered in multiply\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:62: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:64: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:65: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:66: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:68: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Profile printout saved to text file u'SpeedStrut_Iris.txt'. \n",
      "Timer unit: 1e-06 s\r\n",
      "\r\n",
      "Total time: 0.276265 s\r\n",
      "File: <ipython-input-35-66a1765c970c>\r\n",
      "Function: STRUCT at line 277\r\n",
      "\r\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\r\n",
      "==============================================================\r\n",
      "   277                                           def STRUCT(Xsource,ysource,Xtarget,ytarget,n_trees,C,verbos = False):\r\n",
      "   278                                               # Assumption: ysource has all the labels of the problem \r\n",
      "   279                                               #estimator = DecisionTreeClassifier(max_features='sqrt',random_state=0,max_depth=2)\r\n",
      "   280         1           65     65.0      0.0      Estimator = RandomForestClassifier(max_features='sqrt',random_state=0,n_estimators=n_trees)\r\n",
      "   281         1        69801  69801.0     25.3      Estimator = Estimator.fit(Xsource, ysource)\r\n",
      "   282         1            3      3.0      0.0      RF = []\r\n",
      "   283        11           21      1.9      0.0      for rf in range(Estimator.n_estimators):\r\n",
      "   284        10           19      1.9      0.0          estimator = Estimator.estimators_[rf]\r\n",
      "   285        10        50386   5038.6     18.2          dis_node = value_for_all(estimator,C)\r\n",
      "   286        10          182     18.2      0.1          P = list(np.zeros(estimator.tree_.capacity))\r\n",
      "   287        10           46      4.6      0.0          P[0] = range(len(ytarget))\r\n",
      "   288        10          117     11.7      0.0          Q = list(np.zeros(estimator.tree_.capacity))\r\n",
      "   289        10           23      2.3      0.0          Q[0] = dis_node[0,:]\r\n",
      "   290        10           72      7.2      0.0          thresh = np.zeros(estimator.tree_.capacity)\r\n",
      "   291        10           24      2.4      0.0          remain = [0]\r\n",
      "   292        10           18      1.8      0.0          subset = []\r\n",
      "   293       140          136      1.0      0.0          while(len(remain)!=0):\r\n",
      "   294       130          149      1.1      0.1              i = remain[0]\r\n",
      "   295       130          326      2.5      0.1              LF = estimator.tree_.children_left\r\n",
      "   296       130          228      1.8      0.1              LR = estimator.tree_.children_right\r\n",
      "   297       130          171      1.3      0.1              index_left = LF[i]\r\n",
      "   298       130          147      1.1      0.1              index_right = LR[i]\r\n",
      "   299       130          178      1.4      0.1              if(index_left!=-1):\r\n",
      "   300        60          117      1.9      0.0                  QL = dis_node[index_left,:]\r\n",
      "   301        60           86      1.4      0.0                  QR = dis_node[index_right,:]\r\n",
      "   302        60          125      2.1      0.0                  f = estimator.tree_.feature[i]\r\n",
      "   303        60       146162   2436.0     52.9                  [th, ql, qr, left, right] = threshold_selection(Xtarget,ytarget,np.array(P[i]),f,QL,QR,C,verbos)\r\n",
      "   304        60          131      2.2      0.0                  thresh[i] = th\r\n",
      "   305        60           92      1.5      0.0                  P[index_left] = left\r\n",
      "   306        60           73      1.2      0.0                  P[index_right] = right\r\n",
      "   307        60           65      1.1      0.0                  Q[index_left] = ql\r\n",
      "   308        60           52      0.9      0.0                  Q[index_right] = qr\r\n",
      "   309        60           72      1.2      0.0                  if(len(left)!=0):\r\n",
      "   310        60          704     11.7      0.3                      remain = np.append(remain,index_left)\r\n",
      "   311        60           72      1.2      0.0                  if(len(right)!=0):\r\n",
      "   312        60          503      8.4      0.2                      remain = np.append(remain,index_right)\r\n",
      "   313        60           76      1.3      0.0                  if(len(left)>0 and len(right)>0):\r\n",
      "   314        60           99      1.6      0.0                      subset.append(i)\r\n",
      "   315       130          159      1.2      0.1              remain = remain[1:]\r\n",
      "   316        10           48      4.8      0.0          lf =  LF[subset]\r\n",
      "   317        10           30      3.0      0.0          lr =  LR[subset]\r\n",
      "   318        10          109     10.9      0.0          subset = np.append(subset,lf)\r\n",
      "   319        10           71      7.1      0.0          subset = np.append(subset,lr)\r\n",
      "   320        10          251     25.1      0.1          subset = np.unique(np.sort(subset))\r\n",
      "   321        10           19      1.9      0.0          subset = np.array(subset)\r\n",
      "   322        10          863     86.3      0.3          (target_lf,target_lr) = TransferToSKLsequence(np.array(LF),np.array(LR),subset)\r\n",
      "   323        10         4155    415.5      1.5          ST = convert_from_scikit_learn_to_dic_STRUT(estimator,thresh,C,Q,target_lf,target_lr,estimator.tree_.feature[subset])\r\n",
      "   324        10           18      1.8      0.0          RF.append(ST)\r\n",
      "   325         1            1      1.0      0.0      return RF"
     ]
    }
   ],
   "source": [
    "%lprun -s -f STRUCT -T SpeedStrut_Iris.txt STRUCT(Xsource,ysource,Xtarget,ytarget,n_trees=10,C=3,verbos = False) \n",
    "%cat SpeedStrut_Iris.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[th, ql, qr, left, right] = threshold_selection(Xtarget,ytarget,np.array(P[i]),f,QL,QR,C,verbos) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
