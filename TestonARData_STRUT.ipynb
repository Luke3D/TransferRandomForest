{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import STRUTfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version of GraphLab Create (v2.1) is available! Your current version is v2.0.1.\n",
      "You can use pip to upgrade the graphlab-create package. For more information see https://turi.com/products/create/upgrade.\n",
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.0.1 started. Logging: /tmp/graphlab_server_1470408645.log\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create for academic use is assigned to llonini@ricres.org and will expire on November 11, 2016.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphlab\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.338211 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.338211 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 8375 lines in 0.541197 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 8375 lines in 0.541197 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.821949 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.821949 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 22354 lines in 1.45867 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 22354 lines in 1.45867 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.02247 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.02247 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 18762 lines in 1.01648 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 18762 lines in 1.01648 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HealthyData = graphlab.SFrame.read_csv('../Datasets/Cbrace/HealthyData.csv')\n",
    "CBRData = graphlab.SFrame.read_csv('../Datasets/Cbrace/PatientCBRData.csv')\n",
    "SCOData = graphlab.SFrame.read_csv('../Datasets/Cbrace/PatientSCOData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">SubjID</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Session</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  2</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  3</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  4</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  5</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  6</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.051382320442</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.6076</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.196</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0253933701657</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.6076</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1176</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">178</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0248519337017</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.49</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1176</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0465635359116</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.3136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0781834254144</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.2352</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">56</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  8</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  9</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 10</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 11</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 12</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.112454267826</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.294668590342</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.38556796968</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.000653333333333</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.072657333349</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.181289226345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0983200079119</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0523105353163</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.41100727695</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.000435555555556</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0780695955254</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.180121837472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0841222692085</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.592549758023</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.41421963842</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000653333333333</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0698793552525</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.24648779524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0654386480834</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1.01056633159</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.65404790008</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000217777777778</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0504932952633</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.225561487781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0375305142722</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.712656990085</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.19196004385</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000217777777778</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0415385735192</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.130183600125</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 14</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 15</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 16</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 17</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 18</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 19</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 20</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.849714754</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.08929834254</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.7644</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.539</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.89013448447</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6.99232707182</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.7644</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1568</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.91346159405</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6.98496353591</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.49</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1176</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.15285973332</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.01284751381</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.3136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0392</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.15415404049</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.03970276243</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.2352</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 22</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 23</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 24</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 25</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 26</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.252559348905</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.441806399998</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.50225147456</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.00234111111111</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0614360391284</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.350425643783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.163775773499</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.35066706204</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.8748955425</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.00190555555556</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0682046491004</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.272877559768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0861118742405</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.935385885979</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.09906709893</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.061650817028</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.00567046879142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0628676683988</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.924831026921</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.34203744561</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000653333333333</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.048583233193</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.20819575962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0370766090247</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.613014026838</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.89219892908</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000217777777778</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0429608801596</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.164208050896</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 28</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 29</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 30</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 31</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 32</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 33</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 34</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 35</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.98909461353</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.27022541436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8428</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.4606</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.35673213621</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.34927513812</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8428</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.147</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.06132460327</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.35820883978</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.735</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.52215990866</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.33557679558</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.343</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0392</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.73771975026</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.31483977901</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.2254</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 36</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 37</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 38</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.219706356595</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.127990349631</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.71927560428</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.155590412767</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.639652012448</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.13275290921</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0925837130462</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.03393366067</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.73592612692</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0506722377716</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.05044494342</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.46466722648</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0292622124165</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.282918434936</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.74073784939</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[5 rows x 134 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tSubjID\tint\n",
       "\tSession\tint\n",
       "\tFeatures_  1\tfloat\n",
       "\tFeatures_  2\tfloat\n",
       "\tFeatures_  3\tfloat\n",
       "\tFeatures_  4\tint\n",
       "\tFeatures_  5\tint\n",
       "\tFeatures_  6\tint\n",
       "\tFeatures_  7\tint\n",
       "\tFeatures_  8\tfloat\n",
       "\tFeatures_  9\tfloat\n",
       "\tFeatures_ 10\tfloat\n",
       "\tFeatures_ 11\tfloat\n",
       "\tFeatures_ 12\tfloat\n",
       "\tFeatures_ 13\tfloat\n",
       "\tFeatures_ 14\tfloat\n",
       "\tFeatures_ 15\tfloat\n",
       "\tFeatures_ 16\tfloat\n",
       "\tFeatures_ 17\tfloat\n",
       "\tFeatures_ 18\tint\n",
       "\tFeatures_ 19\tint\n",
       "\tFeatures_ 20\tint\n",
       "\tFeatures_ 21\tint\n",
       "\tFeatures_ 22\tfloat\n",
       "\tFeatures_ 23\tfloat\n",
       "\tFeatures_ 24\tfloat\n",
       "\tFeatures_ 25\tfloat\n",
       "\tFeatures_ 26\tfloat\n",
       "\tFeatures_ 27\tfloat\n",
       "\tFeatures_ 28\tfloat\n",
       "\tFeatures_ 29\tfloat\n",
       "\tFeatures_ 30\tfloat\n",
       "\tFeatures_ 31\tfloat\n",
       "\tFeatures_ 32\tint\n",
       "\tFeatures_ 33\tint\n",
       "\tFeatures_ 34\tint\n",
       "\tFeatures_ 35\tint\n",
       "\tFeatures_ 36\tfloat\n",
       "\tFeatures_ 37\tfloat\n",
       "\tFeatures_ 38\tfloat\n",
       "\tFeatures_ 39\tfloat\n",
       "\tFeatures_ 40\tfloat\n",
       "\tFeatures_ 41\tfloat\n",
       "\tFeatures_ 42\tfloat\n",
       "\tFeatures_ 43\tfloat\n",
       "\tFeatures_ 44\tfloat\n",
       "\tFeatures_ 45\tfloat\n",
       "\tFeatures_ 46\tfloat\n",
       "\tFeatures_ 47\tfloat\n",
       "\tFeatures_ 48\tfloat\n",
       "\tFeatures_ 49\tfloat\n",
       "\tFeatures_ 50\tfloat\n",
       "\tFeatures_ 51\tfloat\n",
       "\tFeatures_ 52\tfloat\n",
       "\tFeatures_ 53\tfloat\n",
       "\tFeatures_ 54\tfloat\n",
       "\tFeatures_ 55\tfloat\n",
       "\tFeatures_ 56\tfloat\n",
       "\tFeatures_ 57\tfloat\n",
       "\tFeatures_ 58\tfloat\n",
       "\tFeatures_ 59\tfloat\n",
       "\tFeatures_ 60\tfloat\n",
       "\tFeatures_ 61\tfloat\n",
       "\tFeatures_ 62\tfloat\n",
       "\tFeatures_ 63\tfloat\n",
       "\tFeatures_ 64\tfloat\n",
       "\tFeatures_ 65\tfloat\n",
       "\tFeatures_ 66\tfloat\n",
       "\tFeatures_ 67\tfloat\n",
       "\tFeatures_ 68\tfloat\n",
       "\tFeatures_ 69\tfloat\n",
       "\tFeatures_ 70\tfloat\n",
       "\tFeatures_ 71\tfloat\n",
       "\tFeatures_ 72\tfloat\n",
       "\tFeatures_ 73\tfloat\n",
       "\tFeatures_ 74\tfloat\n",
       "\tFeatures_ 75\tfloat\n",
       "\tFeatures_ 76\tfloat\n",
       "\tFeatures_ 77\tfloat\n",
       "\tFeatures_ 78\tfloat\n",
       "\tFeatures_ 79\tfloat\n",
       "\tFeatures_ 80\tfloat\n",
       "\tFeatures_ 81\tfloat\n",
       "\tFeatures_ 82\tfloat\n",
       "\tFeatures_ 83\tfloat\n",
       "\tFeatures_ 84\tfloat\n",
       "\tFeatures_ 85\tfloat\n",
       "\tFeatures_ 86\tfloat\n",
       "\tFeatures_ 87\tfloat\n",
       "\tFeatures_ 88\tfloat\n",
       "\tFeatures_ 89\tfloat\n",
       "\tFeatures_ 90\tfloat\n",
       "\tFeatures_ 91\tfloat\n",
       "\tFeatures_ 92\tfloat\n",
       "\tFeatures_ 93\tfloat\n",
       "\tFeatures_ 94\tfloat\n",
       "\tFeatures_ 95\tfloat\n",
       "\tFeatures_ 96\tfloat\n",
       "\tFeatures_ 97\tfloat\n",
       "\tFeatures_ 98\tfloat\n",
       "\tFeatures_ 99\tfloat\n",
       "\tFeatures_100\tfloat\n",
       "\tFeatures_101\tfloat\n",
       "\tFeatures_102\tfloat\n",
       "\tFeatures_103\tfloat\n",
       "\tFeatures_104\tfloat\n",
       "\tFeatures_105\tfloat\n",
       "\tFeatures_106\tfloat\n",
       "\tFeatures_107\tfloat\n",
       "\tFeatures_108\tfloat\n",
       "\tFeatures_109\tfloat\n",
       "\tFeatures_110\tfloat\n",
       "\tFeatures_111\tfloat\n",
       "\tFeatures_112\tfloat\n",
       "\tFeatures_113\tfloat\n",
       "\tFeatures_114\tfloat\n",
       "\tFeatures_115\tfloat\n",
       "\tFeatures_116\tfloat\n",
       "\tFeatures_117\tfloat\n",
       "\tFeatures_118\tfloat\n",
       "\tFeatures_119\tfloat\n",
       "\tFeatures_120\tfloat\n",
       "\tFeatures_121\tfloat\n",
       "\tFeatures_122\tfloat\n",
       "\tFeatures_123\tfloat\n",
       "\tFeatures_124\tfloat\n",
       "\tFeatures_125\tfloat\n",
       "\tFeatures_126\tfloat\n",
       "\tFeatures_127\tfloat\n",
       "\tFeatures_128\tfloat\n",
       "\tFeatures_129\tfloat\n",
       "\tFeatures_130\tfloat\n",
       "\tFeatures_131\tfloat\n",
       "\tLabel\tint\n",
       "\n",
       "Rows: 5\n",
       "\n",
       "Data:\n",
       "+--------+---------+-----------------+--------------+--------------+--------------+\n",
       "| SubjID | Session |   Features_  1  | Features_  2 | Features_  3 | Features_  4 |\n",
       "+--------+---------+-----------------+--------------+--------------+--------------+\n",
       "|   1    |    1    |  0.051382320442 |    0.6076    |    0.196     |      0       |\n",
       "|   1    |    1    | 0.0253933701657 |    0.6076    |    0.1176    |      0       |\n",
       "|   1    |    1    | 0.0248519337017 |     0.49     |    0.1176    |      0       |\n",
       "|   1    |    1    | 0.0465635359116 |    0.3136    |    0.0784    |      0       |\n",
       "|   1    |    1    | 0.0781834254144 |    0.2352    |    0.0784    |      56      |\n",
       "+--------+---------+-----------------+--------------+--------------+--------------+\n",
       "+--------------+--------------+--------------+-----------------+-----------------+\n",
       "| Features_  5 | Features_  6 | Features_  7 |   Features_  8  |   Features_  9  |\n",
       "+--------------+--------------+--------------+-----------------+-----------------+\n",
       "|     181      |      0       |      0       |  0.112454267826 | -0.294668590342 |\n",
       "|     178      |      3       |      0       | 0.0983200079119 | 0.0523105353163 |\n",
       "|     181      |      0       |      0       | 0.0841222692085 | -0.592549758023 |\n",
       "|     181      |      0       |      0       | 0.0654386480834 |  -1.01056633159 |\n",
       "|      0       |      0       |      0       | 0.0375305142722 | -0.712656990085 |\n",
       "+--------------+--------------+--------------+-----------------+-----------------+\n",
       "+---------------+--------------------+-----------------+----------------+\n",
       "|  Features_ 10 |    Features_ 11    |   Features_ 12  |  Features_ 13  |\n",
       "+---------------+--------------------+-----------------+----------------+\n",
       "| 2.38556796968 | -0.000653333333333 |  0.072657333349 | 0.181289226345 |\n",
       "| 3.41100727695 | -0.000435555555556 | 0.0780695955254 | 0.180121837472 |\n",
       "| 3.41421963842 | 0.000653333333333  | 0.0698793552525 | 0.24648779524  |\n",
       "| 3.65404790008 | 0.000217777777778  | 0.0504932952633 | 0.225561487781 |\n",
       "| 4.19196004385 | 0.000217777777778  | 0.0415385735192 | 0.130183600125 |\n",
       "+---------------+--------------------+-----------------+----------------+\n",
       "+---------------+---------------+--------------+--------------+--------------+-----+\n",
       "|  Features_ 14 |  Features_ 15 | Features_ 16 | Features_ 17 | Features_ 18 | ... |\n",
       "+---------------+---------------+--------------+--------------+--------------+-----+\n",
       "|  4.849714754  | 7.08929834254 |    0.7644    |    0.539     |      0       | ... |\n",
       "| 3.89013448447 | 6.99232707182 |    0.7644    |    0.1568    |      0       | ... |\n",
       "| 4.91346159405 | 6.98496353591 |     0.49     |    0.1176    |      0       | ... |\n",
       "| 4.15285973332 | 7.01284751381 |    0.3136    |    0.0392    |      0       | ... |\n",
       "| 4.15415404049 | 7.03970276243 |    0.2352    |    0.0784    |      0       | ... |\n",
       "+---------------+---------------+--------------+--------------+--------------+-----+\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBRData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
      "[1, 2, 5, 6, 8, 11, 12, 13, 14, 15, 16, 19]\n"
     ]
    }
   ],
   "source": [
    "#SUBJECTS IN THE DATABASE\n",
    "HealthyCodes = HealthyData['SubjID'].unique()\n",
    "HealthyCodes = HealthyCodes.sort()\n",
    "print HealthyCodes\n",
    "PatientCodes = CBRData['SubjID'].unique()\n",
    "PatientCodes = PatientCodes.sort()\n",
    "print PatientCodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STRUT Fcns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import log\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def convert_from_scikit_learn_to_dic_ite_strut(node_index,is_leaves, children_left,children_right,feature,threshold,value,labels,C):\n",
    "        \n",
    "        a = is_leaves[0]\n",
    "        b = feature[0]\n",
    "        c = threshold[0]\n",
    "        if (a):\n",
    "            d = value[0]  #datapoints of each class in the node\n",
    "            d2 = np.squeeze(d/np.sum(d))\n",
    "            d3 = np.zeros(C)\n",
    "            d3[labels] = d2\n",
    "            e = labels[np.argmax(d2)]\n",
    "            return {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True,\n",
    "            'prediction': e,\n",
    "            'labels_distribution':d3}\n",
    "    \n",
    "        else:\n",
    "            left = children_left[0]-node_index[0]\n",
    "            if(left==-1):\n",
    "                left_tree = None\n",
    "            else:\n",
    "                left_tree = convert_from_scikit_learn_to_dic_ite_strut(node_index[left:],is_leaves[left:], children_left[left:],children_right[left:],feature[left:],threshold[left:],value[left:],labels,C)\n",
    "            right = children_right[0]-node_index[0]\n",
    "            if(right==-1):\n",
    "                right_tree = None\n",
    "            else:\n",
    "                right_tree = convert_from_scikit_learn_to_dic_ite_strut(node_index[right:],is_leaves[right:], children_left[right:],children_right[right:],feature[right:],threshold[right:],value[right:],labels,C)\n",
    "            return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': b,\n",
    "            'threshold'        : c,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree,\n",
    "            'labels_distribution': None}\n",
    "\n",
    "def convert_from_scikit_learn_to_dic_strut(feature,threshold,C,Q,children_left,children_right):\n",
    "    # C is the size of the whole labels\n",
    "    # labels are the labels that are used in the this tree\n",
    "    labels = range(0,C,1)\n",
    "    n_nodes = len(children_left)\n",
    "    node_index = np.array(range(0,n_nodes))\n",
    "    Val = Q   #datapoints in node\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "    # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "            \n",
    "    return convert_from_scikit_learn_to_dic_ite_strut(node_index,is_leaves, children_left,children_right,feature,threshold,Val,labels,C)\n",
    "\n",
    "def treesubset(subset,children_left,children_right):\n",
    "    ch_left = np.zeros(len(children_left))\n",
    "    ch_right = np.zeros(len(children_right))  \n",
    "    for i in range(len(subset)):\n",
    "        (l,) = np.where(subset==children_left[i])\n",
    "        (r,) = np.where(subset==children_right[i])\n",
    "        if(l.shape[0]==0):\n",
    "            ch_left[i] = -1\n",
    "        else:\n",
    "            ch_left[i] = l\n",
    "            \n",
    "        if(r.shape[0]==0):\n",
    "            ch_right[i] = -1\n",
    "        else:\n",
    "            ch_right[i] = r        \n",
    "    return (ch_left,ch_right)\n",
    "\n",
    "def kl (p,q): # Kullback-libler divegence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    return np.sum(np.where(p != 0,p * np.log10((p / q)), 0))\n",
    "\n",
    "def jsd(p,q): # Symmetric Kullback-libler divergence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    m = (p+q)/2\n",
    "    return (kl(p,m)+kl(m,q))/2\n",
    "\n",
    "def infogain(yleft,len_left,yright,len_right):\n",
    "    N = len_left+len_right\n",
    "    yparent = (len_left/N)*yleft+(len_right/N)*yright\n",
    "    #compute information gain\n",
    "    I = entropy(yparent) -( (len_left/N)*entropy(yleft) + (len_right/N)*entropy(yright) )   \n",
    "    return I\n",
    "\n",
    "#entropy for multiple classes\n",
    "def entropy(y):\n",
    "    y1 = y[y!=0]\n",
    "    H = -(y1*np.log10(y1)).sum()\n",
    "    return H \n",
    "\n",
    "#computes split for given feature\n",
    "def partition(Xtarget,ytarget,index_of_data,feature,num_class_target,index_class_target,threshold): # divide the data to the left and rightbased on the threshold\n",
    "    left = index_of_data[Xtarget[index_of_data,feature]<threshold]\n",
    "    if(len(left)==0):\n",
    "        left = index_of_data[Xtarget[index_of_data,feature]<=threshold]\n",
    "    labels_left = ytarget[left]\n",
    "    right = index_of_data[Xtarget[index_of_data,feature]>=threshold]\n",
    "    labels_right = ytarget[right]\n",
    "    \n",
    "    qL_full = np.bincount(labels_left)\n",
    "    qR_full = np.bincount(labels_right)\n",
    "    qL_full = np.append(qL_full,np.zeros(np.max([num_class_target-qL_full.shape[0],0])))\n",
    "    qR_full = np.append(qR_full,np.zeros(np.max([num_class_target-qR_full.shape[0],0])))\n",
    "    \n",
    "    qL = qL_full[index_class_target]\n",
    "    qR = qR_full[index_class_target]\n",
    " \n",
    "    qL = qL/qL.sum()\n",
    "    qR = qR/qR.sum()\n",
    "    \n",
    "    return [qL,left,qR,right]\n",
    "\n",
    "def dg(Sleft,lenleft,Sright,lenright,QL,QR): # DG function as in the paper    \n",
    "    return 1-(lenleft/(lenleft+lenright))*jsd(Sleft,QL)-(lenright/(lenleft+lenright))*jsd(Sright,QR)\n",
    "    \n",
    "#optimize threshold of given node based on target data\n",
    "#INPUTS: Xtarget, ytarget, S:indices of datapoints that reach node, f:feature of node, QL,QR:Distributions from source reaching children\n",
    "#        C:# of classes, verbos: print additional info\n",
    "#OUTPUTS: [th, ql, qr, left, right]: th: new threshold; ql,qr: distribution from target with new threshold; left,right: target data indices\n",
    "#         going to left and right nodes\n",
    "#Depending fcns: partition(), df(), infogain(), jsd(), kl(), entropy()\n",
    "\n",
    "def threshold_selection(X,y,S,f,QL,QR,num_class_target,index_class_target,verbos): # finding the best threshold\n",
    "    fvals = np.sort(X[S,f])\n",
    "    num_data_points = len(fvals)\n",
    "    N = 50 # # of bins to search threshold\n",
    "    Val_DG  = np.array([]) #contains values of DG for each bin\n",
    "    Val_infogain = np.array([])\n",
    "    if num_data_points > N-1: \n",
    "        I = range(0,num_data_points,np.floor(num_data_points/N).astype(int))\n",
    "        fvals = fvals[I[1:-1]]\n",
    "    for i in fvals:\n",
    "        [qL, left, qR, right] = partition(X,y,S,f,num_class_target,index_class_target,i) #compute histogram (qL,qR) for left and right children with current threshold\n",
    "        #fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex='col', sharey='row')\n",
    "        #ax1.plot(QL)\n",
    "        #ax1.set_title('QL')\n",
    "        #ax2.plot(Sleft, color='r')\n",
    "        #ax2.set_title('QprimeL')\n",
    "        #ax3.plot(QR)\n",
    "        #ax3.set_title('QR')\n",
    "        #ax4.plot(Sright, color='r')\n",
    "        #ax4.set_title('QprimeR')\n",
    "        Val_DG = np.append(Val_DG,dg(qL,len(left),qR,len(right),QL,QR))\n",
    "        Val_infogain = np.append(Val_infogain,infogain(qL,len(left),qR,len(right)))        #Val_swap = np.append(Val_swap,dg(Sleft,len(left),Sright,len(right),QR,QL)) # this is the divergence measure for each threshold split  \n",
    "    if(verbos):\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex='col', sharey='row')\n",
    "    #ax1.plot(Val)\n",
    "    #ax1.set_title('DG')\n",
    "    #ax2.plot(Val_infogain)\n",
    "    #ax2.set_title('infogain')\n",
    "        ax1.plot(fvals,Val_DG,'r')\n",
    "        ax1.hold(True)\n",
    "        ax1.plot(fvals,Val_infogain)\n",
    "        ax1.hold(False)\n",
    "        ax1.set_title('DG and Infogain')\n",
    "    #plt.show()\n",
    "    #find nan and assign the minimum value found in the array to remove the nan \n",
    "    Val_DG[np.isnan(Val_DG)] = min(Val_DG[~np.isnan(Val_DG)])\n",
    "    Val_infogain[np.isnan(Val_infogain)] = min(Val_infogain[~np.isnan(Val_infogain)])\n",
    "    #Val_swap[np.isnan(Val_swap)] = min(Val_swap[~np.isnan(Val_swap)])\n",
    "    th_DG = fvals[np.argmax(Val_DG)]\n",
    "    th_infogain = fvals[np.argmax(Val_infogain)]\n",
    "\n",
    "    #plt.plot(Val_infogain)\n",
    "    #plt.show()\n",
    "    \n",
    "    #find new threshold based on how many datapoints we have in current node\n",
    "    #Set DG vs IG\n",
    "    if(len(S)>0):\n",
    "        [ql, left, qr, right] = partition(X,y,S,f,num_class_target,index_class_target,th_infogain)\n",
    "        th = th_infogain\n",
    "    else:\n",
    "        [ql, left, qr, right] = partition(X,y,S,f,num_class_target,index_class_target,th_DG)\n",
    "        th = th_DG\n",
    "        \n",
    "    if(verbos):\n",
    "        ax2.plot(ql)\n",
    "        ax2.hold(True)\n",
    "        ax2.plot(qr)\n",
    "        ax2.hold(False)\n",
    "        ax2.set_title('Dist Target Data')\n",
    "\n",
    "        ax3.plot(QL)\n",
    "        ax3.hold(True)\n",
    "        ax3.plot(QR)\n",
    "        ax3.hold(False)\n",
    "        ax3.set_title('Dist Source Data')\n",
    "        \n",
    "    return [th, ql, qr, left, right]\n",
    "\n",
    "def classify(tree, x):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        return tree['labels_distribution'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        val_split_feature = x[tree['splitting_feature']]\n",
    "        if val_split_feature < tree['threshold']:\n",
    "            return classify(tree['left'], x)\n",
    "        else:\n",
    "            return classify(tree['right'],x)\n",
    "\n",
    "def forest_posterior(RF,x):\n",
    "\n",
    "    T = len(RF)  #the number of trees \n",
    "\n",
    "    #infer the number of classes\n",
    "    P0 = classify(RF[0],x)\n",
    "    C = len(P0)\n",
    "    \n",
    "    Pt = np.zeros((T,C)) #matrix of posteriors from each tree (T x Nclasses)\n",
    "    Pt[0,:] = P0\n",
    "    for t in range(len(RF))[1:]:\n",
    "        Pt[t,:] = classify(RF[t],x) \n",
    "    return Pt\n",
    "\n",
    "#classify input based on majority voting of each tree prediction\n",
    "def forest_classify_majority(RF,x):\n",
    "        Pt = forest_posterior(RF,x)\n",
    "        Yt = np.argmax(Pt,axis=1)         \n",
    "        C,unique_counts = np.unique(Yt,return_counts=True) #the id of classes and number of each\n",
    "        return C[np.argmax(unique_counts)]   \n",
    "    \n",
    "#classify input by averaging posteriors \n",
    "def forest_classify_ensemble(RF,x):\n",
    "    Pt = forest_posterior(RF,x)\n",
    "    Pforest = Pt.mean(axis=0)\n",
    "    ypred = np.argmax(Pt.mean(axis=0))\n",
    "    return ypred\n",
    "\n",
    "def evaluate_classification_error(RF, X, y, method = None):  \n",
    "    # Apply the forest_classify(RF, x) to each row in your data\n",
    "    if method == None:\n",
    "        ypred = map(lambda x: forest_classify_ensemble(RF,x), X)\n",
    "        # Once you've made the predictions, calculate the classification error and return it\n",
    "        mistakes = sum(ypred != y)\n",
    "        error = mistakes/len(y)\n",
    "    return error\n",
    "\n",
    "#returning the histogram of the classes for each node in estimator. N is # of classes\n",
    "def value_for_all(estimator,N):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    ch_left = estimator.tree_.children_left\n",
    "    ch_right = estimator.tree_.children_right\n",
    "    (cl,) = np.where(ch_left!=-1)\n",
    "    (cr,) = np.where(ch_right!=-1)\n",
    "    cap = estimator.tree_.capacity\n",
    "    dis_node = np.zeros((cap,estimator.tree_.n_classes))\n",
    "    A = np.zeros([cap,cap])\n",
    "    D = A\n",
    "    A = csr_matrix(A)\n",
    "    A[cl,ch_left[cl]] = 1\n",
    "    A[cr,ch_right[cr]] = 1\n",
    "    B = A\n",
    "    C = B\n",
    "    while(C.sum()!=0):\n",
    "        C = A*C\n",
    "        B = B + C\n",
    "    I,J = B.nonzero()\n",
    "    D[I,J] = 1\n",
    "    (I,) = np.where(ch_left==-1)\n",
    "    dis_node[I,:] = np.squeeze(estimator.tree_.value[I])\n",
    "    for i in I:\n",
    "        dis_node[i,:] = dis_node[i,:]/dis_node[i,:].sum()\n",
    "    (remain1,) = np.where(ch_left!=-1)\n",
    "    for i in remain1:\n",
    "        (I,) = np.where(D[i,:]==1)\n",
    "        dis_node[i,:] = np.sum(np.squeeze(estimator.tree_.value[I]),axis = 0)\n",
    "        dis_node[i,:] = dis_node[i,:]/dis_node[i,:].sum()\n",
    "    Dis_node = np.zeros((cap,N))\n",
    "    Dis_node[:,estimator.classes_.astype(int)] = dis_node\n",
    "    return Dis_node\n",
    "    \n",
    "def STRUT(Xsource,ysource,Xtarget,ytarget,n_trees,verbos = False):\n",
    "    # Assumption: ysource has all the labels of the problem \n",
    "    \n",
    "    #Train RF on Source\n",
    "    Estimator = RandomForestClassifier(n_estimators=n_trees,criterion='entropy',random_state=0)  \n",
    "    Estimator = Estimator.fit(Xsource, ysource)\n",
    "    #Infer classes of source and target\n",
    "    C = len(np.unique(ysource)) # Number of classes in source data\n",
    "    index_class_target = np.sort(np.unique(ytarget)) #the indices of classes in the target data\n",
    "    max_index_target = max(index_class_target)+1\n",
    "\n",
    "    # ypred = Estimator.predict(Xtarget)\n",
    "    # print sum(ypred!=ytarget)/len(ytarget)\n",
    "   \n",
    "    RF = []\n",
    "    \n",
    "    # Looping through all the trees in the forest RF\n",
    "    for rf in range(Estimator.n_estimators):\n",
    "        estimator = Estimator.estimators_[rf] \n",
    "        #print '#leaves before STRUT = %s'%(estimator.tree_.node_count)\n",
    "\n",
    "        dis_node = value_for_all(estimator,C)  #Histogram of classes for source (row: node index, col: class)\n",
    "        \n",
    "        #if the target data contains a different # of classes than source\n",
    "        if len(index_class_target) < C:\n",
    "            dis_node = dis_node[:,index_class_target]/np.sum(dis_node[:,index_class_target],axis=1)[:,None]\n",
    "        dis_node[np.isnan(dis_node)] = 1/len(index_class_target)\n",
    "        #if(np.any(np.isnan(dis_node))):\n",
    "         #   print 'nan found'    \n",
    "            \n",
    "        LF = estimator.tree_.children_left  #indices of left nodes \n",
    "        LR = estimator.tree_.children_right #indices of right nodes\n",
    "        Features = estimator.tree_.feature\n",
    "        num_nodes = estimator.tree_.capacity\n",
    "        P = list(np.zeros(num_nodes)) #maintain a list of the target data indices at each node (0 is root) - capacity is node_count\n",
    "        P[0] = range(len(ytarget))\n",
    "        Q = np.zeros((num_nodes,len(index_class_target))) #Histogram of target data indices at each node\n",
    "        Q[0,:] = dis_node[0,:]\n",
    "        thresh = np.zeros(num_nodes) #init vector with new threshold at each node\n",
    "        remain = [0]    #indexing the remaining nodes as we move from top-down\n",
    "        subset = []     #maintains a list of the nodes that are reached from target data\n",
    "        #looping through the nodes\n",
    "        while(len(remain)!=0):\n",
    "            i = remain[0]\n",
    "            subset.append(i)  #updating the list of nodes reached by target data with current node index\n",
    "            index_left = LF[i] \n",
    "            index_right = LR[i]\n",
    "            #check if node is leaf\n",
    "            if(index_left!=-1):\n",
    "                QL = dis_node[index_left,:]  #distribution of labels in children nodes\n",
    "                QR = dis_node[index_right,:]\n",
    "                f = Features[i]  #feature of parent node\n",
    "                [th, ql, qr, left, right] = threshold_selection(Xtarget,ytarget,np.array(P[i]),f,QL,QR,max_index_target,index_class_target,verbos)\n",
    "                thresh[i] = th\n",
    "                P[index_left] = left\n",
    "                P[index_right] = right\n",
    "                Q[index_left,:] = ql\n",
    "                Q[index_right,:] = qr\n",
    "                \n",
    "                #if no target datapoints reach either the left or right children we make the parent node a leaf\n",
    "                if(len(left)>0 and len(right)>0):\n",
    "                    remain = np.append(remain,index_left)\n",
    "                    remain = np.append(remain,index_right)\n",
    "            remain = remain[1:]\n",
    "\n",
    "        subset = np.sort(subset)\n",
    "        lf =  LF[subset]\n",
    "        lr =  LR[subset]\n",
    "        (ch_lf,ch_lr) = treesubset(subset,lf,lr)\n",
    "        Qnew = np.zeros((Q.shape[0],C))\n",
    "        Qnew[:,index_class_target] = Q  #Histogram of target data on the full set of class labels (includes the missing classes)\n",
    "        ST = convert_from_scikit_learn_to_dic_strut(Features[subset],thresh[subset],C,Qnew[subset,:],ch_lf.astype(int),ch_lr.astype(int))\n",
    "        #print 'tree trained'\n",
    "        RF.append(ST)\n",
    "        #print '#leaves after STRUT = %s'%(sum(lf==-1))\n",
    "\n",
    "    return RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  5,  6,  8, 11, 14, 15, 16, 19])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PatientCodes = np.array([1, 2, 5, 6, 8, 11, 14, 15, 16, 19]) #all patient with 4 sessions in CBR (06 Missing Stairs UP!)\n",
    "PatientCodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Source (Healthy) only\n",
    "should test on 3 sessions and keep 1 (target) out -> Cross validation with leave one session out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1\n",
      "Train samples = 8375, Test samples = 1288\n",
      "BAcc = 0.44\n",
      "Test on Patient 2\n",
      "Train samples = 8375, Test samples = 991\n",
      "BAcc = 0.37\n",
      "Test on Patient 5\n",
      "Train samples = 8375, Test samples = 1358\n",
      "BAcc = 0.49\n",
      "Test on Patient 6\n",
      "Train samples = 8375, Test samples = 2035\n",
      "BAcc = 0.54\n",
      "Test on Patient 8\n",
      "Train samples = 8375, Test samples = 856\n",
      "BAcc = 0.36\n",
      "Test on Patient 11\n",
      "Train samples = 8375, Test samples = 1253\n",
      "BAcc = 0.52\n",
      "Test on Patient 14\n",
      "Train samples = 8375, Test samples = 1658\n",
      "BAcc = 0.50\n",
      "Test on Patient 15\n",
      "Train samples = 8375, Test samples = 1906\n",
      "BAcc = 0.50\n",
      "Test on Patient 16\n",
      "Train samples = 8375, Test samples = 1126\n",
      "BAcc = 0.53\n",
      "Test on Patient 19\n",
      "Train samples = 8375, Test samples = 1020\n",
      "BAcc = 0.68\n",
      "\n",
      "mean Bacc Source only = 0.493096021861\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=50,criterion='entropy',random_state=0)\n",
    "RF = RF.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)  & (CBRData['Session'] != 4)] #keep out one session (used later for target)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "    print 'Test on Patient %s'%s\n",
    "    print 'Train samples = %s, Test samples = %s'%(len(ytrain),len(ytest))\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #SOacc[k] = acc\n",
    "\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    SOacc[k] = BAcc\n",
    "\n",
    "    print 'BAcc = {:.2f}'.format(SOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmean Bacc Source only = %s'%SOacc.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on target only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, BAcc Target only = 0.72\n",
      "Patient 2, BAcc Target only = 0.45\n",
      "Patient 5, BAcc Target only = 0.57\n",
      "Patient 6, BAcc Target only = 0.65\n",
      "Patient 8, BAcc Target only = 0.76\n",
      "Patient 11, BAcc Target only = 0.49\n",
      "Patient 14, BAcc Target only = 0.46\n",
      "Patient 15, BAcc Target only = 0.84\n",
      "Patient 16, BAcc Target only = 0.59\n",
      "Patient 19, BAcc Target only = 0.86\n",
      "\n",
      "mean Bacc Target only = 0.64\n"
     ]
    }
   ],
   "source": [
    "TOacc = np.zeros(len(PatientCodes))\n",
    "Ntarget = np.zeros(len(PatientCodes)) #store # of target datapoints in each session\n",
    "k = 0\n",
    "                   \n",
    "for s in PatientCodes:\n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 4)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)]\n",
    "    Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Ntarget[k] = len(ytarget)\n",
    "\n",
    "    RF = RandomForestClassifier(n_estimators=50,criterion='entropy',random_state=0,class_weight=None)\n",
    "    RF = RF.fit(Xtarget,ytarget)\n",
    "    ypred = RF.predict(Xtest)\n",
    "                   \n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #TOacc[k] = acc\n",
    "\n",
    "        #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    BAcc = acc_c/len(np.unique(ytest))           \n",
    "    TOacc[k] = BAcc\n",
    "                   \n",
    "                   \n",
    "    print 'Patient {}, BAcc Target only = {:.2f}'.format(s,TOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmean Bacc Target only = {:.2f}'.format(TOacc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use each of the 4 sessions as target and compute mean accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Acc = 0.87, minAcc = 0.85, MaxAcc = 0.88\n",
      "Patient 2, Acc = 0.66, minAcc = 0.55, MaxAcc = 0.73\n",
      "Patient 5, Acc = 0.69, minAcc = 0.62, MaxAcc = 0.78\n",
      "Patient 6, Acc = 0.82, minAcc = 0.70, MaxAcc = 0.88\n",
      "Patient 8, Acc = 0.79, minAcc = 0.63, MaxAcc = 0.88\n",
      "Patient 11, Acc = 0.57, minAcc = 0.23, MaxAcc = 0.88\n",
      "Patient 14, Acc = 0.79, minAcc = 0.68, MaxAcc = 0.93\n",
      "Patient 15, Acc = 0.88, minAcc = 0.73, MaxAcc = 0.96\n",
      "Patient 16, Acc = 0.74, minAcc = 0.67, MaxAcc = 0.81\n",
      "Patient 19, Acc = 0.82, minAcc = 0.72, MaxAcc = 0.90\n",
      "\n",
      "mean acc Target only (over 4 sessions) = 0.76\n"
     ]
    }
   ],
   "source": [
    "TOacc = np.zeros(len(PatientCodes))\n",
    "TOacc_all = np.zeros((len(PatientCodes),4)) #store accuracy for each target session \n",
    "Ntarget = np.zeros((len(PatientCodes),4)) #store # of target datapoints in each session\n",
    "k = 0\n",
    "                   \n",
    "for s in PatientCodes:\n",
    "    for session in range(4):\n",
    "        target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == session+1)]\n",
    "        test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != session+1)]\n",
    "        Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "        Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "        ytarget = target.select_columns(label_cols).to_numpy()\n",
    "        ytarget = ytarget.reshape(-1)\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "        Ntarget[k,session] = len(ytarget)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50,criterion='entropy')\n",
    "        RF = RF.fit(Xtarget,ytarget)\n",
    "        ypred = RF.predict(Xtest)\n",
    "        acc = sum(ypred == ytest)/len(ytest)\n",
    "        TOacc_all[k,session] = acc\n",
    "\n",
    "        #balanced accuracy\n",
    "#        acc_c = 0\n",
    "#        for c in np.unique(ytest):\n",
    "#            i = ytest == c\n",
    "#            correct = ypred[i] == ytest[i]\n",
    "#            acc_c += sum(correct)/len(correct)\n",
    "#        BAcc = acc_c/len(np.unique(ytest))           \n",
    "#        TOacc_all[k,session] = BAcc\n",
    "                   \n",
    "    TOacc[k]=TOacc_all[k,:].mean()   \n",
    "\n",
    "    print 'Patient {}, Acc = {:.2f}, minAcc = {:.2f}, MaxAcc = {:.2f}'.format(s,TOacc[k],TOacc_all[k,:].min(),TOacc_all[k,:].max())\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmean acc Target only (over 4 sessions) = {:.2f}'.format(TOacc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now test the STRUT - Use one session of data from each patient as target and the remaining as his test\n",
    "* Need to compute CV error on each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:266: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/scipy/sparse/compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 390, Test samples = 1288\n",
      "Acc Target Only = 0.72, Acc w STRUT = 0.48, Acc/class=[ 0.26836158  0.21875     0.15789474  0.78971963  0.98730159]\n",
      "\n",
      "Patient 2,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 467, Test samples = 991\n",
      "Acc Target Only = 0.41, Acc w STRUT = 0.43, Acc/class=[ 0.53811659  0.03773585  0.          0.57966102  0.98659517]\n",
      "\n",
      "Patient 5,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 415, Test samples = 1358\n",
      "Acc Target Only = 0.60, Acc w STRUT = 0.63, Acc/class=[ 0.71614583  0.39130435  0.35384615  0.86391753  0.81927711]\n",
      "\n",
      "Patient 6,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 881, Test samples = 2035\n",
      "Acc Target Only = 0.66, Acc w STRUT = 0.38, Acc/class=[ 0.01084599  0.          0.00847458  0.91626409  0.94878706]\n",
      "\n",
      "Patient 8,  \n",
      "# of classes in test = 3\n",
      "Source samples = 8375, Target samples = 354, Test samples = 856\n",
      "Acc Target Only = 0.80, Acc w STRUT = 0.86, Acc/class=[ 0.90384615  0.          0.          0.75        0.93564356]\n",
      "\n",
      "Patient 11,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 455, Test samples = 1253\n",
      "Acc Target Only = 0.54, Acc w STRUT = 0.49, Acc/class=[ 0.98283262  0.          0.35714286  0.64321608  0.46099291]\n",
      "\n",
      "Patient 14,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 318, Test samples = 1658\n",
      "Acc Target Only = 0.48, Acc w STRUT = 0.52, Acc/class=[ 1.          0.          0.37931034  0.24660194  0.99324324]\n",
      "\n",
      "Patient 15,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 1605, Test samples = 1906\n",
      "Acc Target Only = 0.70, Acc w STRUT = 0.64, Acc/class=[ 0.47692308  1.          0.          0.79868709  0.90189873]\n",
      "\n",
      "Patient 16,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 608, Test samples = 1126\n",
      "Acc Target Only = 0.53, Acc w STRUT = 0.52, Acc/class=[ 0.41044776  0.17721519  0.39759036  0.99378882  0.59654179]\n",
      "\n",
      "Patient 19,  \n",
      "# of classes in test = 3\n",
      "Source samples = 8375, Target samples = 545, Test samples = 1020\n",
      "Acc Target Only = 0.86, Acc w STRUT = 0.74, Acc/class=[ 0.99384615  0.          0.          0.25490196  0.97954545]\n",
      "\n",
      "mean Acc - Source only = 0.497635420273\n",
      "mean Acc - Target only = 0.631022038398\n",
      "mean Acc w STRUT = 0.56878140949\n"
     ]
    }
   ],
   "source": [
    "STRUTacc = np.zeros(len(PatientCodes)) #to store acc when using source + Target with STRUT\n",
    "#STRUTacc_all = np.zeros((len(PatientCodes),4)) #store acc for each session used as target \n",
    "k = 0\n",
    "cmat_subj = [] #confusion matrix for each subject (a list)\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "for s in PatientCodes:\n",
    "    #loop through all 4 sessions and use one as target \n",
    "    #for session in range(4):\n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 4)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)]\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test\n",
    "\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "\n",
    "    STRUT_RF = STRUT(Xtrain,ytrain,Xtarget,ytarget,n_trees=50,verbos = False)\n",
    "    ypred = np.asarray(map(lambda x:forest_classify_ensemble(STRUT_RF,x),Xtest))\n",
    "\n",
    "    #STRUTacc_all[k,session] = sum(ypred==ytest)/len(ytest)\n",
    "\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    acc_class = np.zeros(5) #the accuracy per class\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "        acc_class[c] = sum(correct)/len(correct)\n",
    "\n",
    "    #STRUTacc_all[k,session] = acc_c/len(np.unique(ytest))        \n",
    "    #STRUTacc[k]=STRUTacc_all[k,:].mean()\n",
    "    STRUTacc[k]=acc_c/len(np.unique(ytest))\n",
    "    acc_class_subj.append(acc_class)    \n",
    "\n",
    "   \n",
    "    print 'Patient %s,  '%s\n",
    "    print '# of classes in test = %s'%Nclasses\n",
    "    print 'Source samples = %s, Target samples = %s, Test samples = %s'%(len(ytrain),len(ytarget),len(ytest))\n",
    "    #print 'Acc Target Only = %s, Acc w STRUT = %s, minAcc_STRUT = %s, MaxAcc_STRUT = %s\\n'%(TOacc[k],STRUTacc[k],STRUTacc_all[k,:].min(),STRUTacc_all[k,:].max())\n",
    "    print 'Acc Target Only = {:.2f}, Acc w STRUT = {:.2f}, Acc/class={}\\n'.format(TOacc[k],STRUTacc[k],acc_class)\n",
    "\n",
    "    k = k+1\n",
    "\n",
    "\n",
    "print 'mean Acc - Source only = %s'%SOacc.mean()\n",
    "print 'mean Acc - Target only = %s'%TOacc.mean()\n",
    "print 'mean Acc w STRUT = %s'%STRUTacc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEKCAYAAADkYmWmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ee8cf90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(np.asarray(acc_class_subj))\n",
    "plt.title('acc per class across subjects')\n",
    "plt.axis([0,6,-0.1,1.1])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIX Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a forest with SER, another with STRUT and use mix to compute final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import SERfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:267: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 390, Test samples = 1288\n",
      "Source Only=0.44, Target Only=0.72, SER=0.64, STRUT=0.51, MIX=0.64, MIXmax=0.00\n",
      "Test on Patient 2,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 467, Test samples = 991\n",
      "Source Only=0.37, Target Only=0.45, SER=0.42, STRUT=0.45, MIX=0.51, MIXmax=0.00\n",
      "Test on Patient 5,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 415, Test samples = 1358\n",
      "Source Only=0.49, Target Only=0.57, SER=0.59, STRUT=0.54, MIX=0.64, MIXmax=0.00\n",
      "Test on Patient 6,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 881, Test samples = 2035\n",
      "Source Only=0.54, Target Only=0.65, SER=0.61, STRUT=0.41, MIX=0.60, MIXmax=0.00\n",
      "Test on Patient 8,  \n",
      "# of classes in test = 3\n",
      "Source samples = 8375, Target samples = 354, Test samples = 856\n",
      "Source Only=0.36, Target Only=0.76, SER=0.77, STRUT=0.86, MIX=0.86, MIXmax=0.00\n",
      "Test on Patient 11,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 455, Test samples = 1253\n",
      "Source Only=0.52, Target Only=0.49, SER=0.54, STRUT=0.47, MIX=0.53, MIXmax=0.00\n",
      "Test on Patient 14,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 318, Test samples = 1658\n",
      "Source Only=0.50, Target Only=0.46, SER=0.54, STRUT=0.56, MIX=0.65, MIXmax=0.00\n",
      "Test on Patient 15,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 1605, Test samples = 1906\n",
      "Source Only=0.50, Target Only=0.84, SER=0.54, STRUT=0.52, MIX=0.70, MIXmax=0.00\n",
      "Test on Patient 16,  \n",
      "# of classes in test = 5\n",
      "Source samples = 8375, Target samples = 608, Test samples = 1126\n",
      "Source Only=0.53, Target Only=0.59, SER=0.53, STRUT=0.40, MIX=0.54, MIXmax=0.00\n",
      "Test on Patient 19,  \n",
      "# of classes in test = 3\n",
      "Source samples = 8375, Target samples = 545, Test samples = 1020\n",
      "Source Only=0.68, Target Only=0.86, SER=0.72, STRUT=0.78, MIX=0.84, MIXmax=0.00\n",
      "\n",
      "mean Acc - Source only = 0.493096021861\n",
      "mean Acc - Target only = 0.638666442112\n",
      "mean Acc - SER = 0.58953248995\n",
      "mean Acc - STRUT = 0.551282948826\n",
      "mean Acc - MIX = 0.651334709665\n"
     ]
    }
   ],
   "source": [
    "#train forest w SER\n",
    "SERacc = np.zeros(len(PatientCodes)) #to store err when using source + Target with SER\n",
    "STRUTacc = np.zeros(len(PatientCodes)) #to store err when using source + Target with STRUT\n",
    "MIXacc = np.zeros(len(PatientCodes)) #to store err when using source + Target with MIX\n",
    "MIXmaxacc = np.zeros(len(PatientCodes)) #to store err when using source + Target with MIX\n",
    "\n",
    "k = 0\n",
    "cmat_subj = [] #confusion matrix for each subject (a list)\n",
    "acc_class_subj = [] #accuracy per class for each subject\n",
    "\n",
    "#train forest on healthy (Source)\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "RF = RandomForestClassifier(n_estimators=50,criterion='entropy',random_state=0)\n",
    "RF = RF.fit(Xtrain,ytrain)\n",
    "\n",
    "for s in PatientCodes:\n",
    "    #loop through target sessions (use one as target)\n",
    "    #for session in range(4):\n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 4)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)]\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient in test\n",
    "\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "\n",
    "    #predicting using only source data\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #correct = sum(ypred == ytest)\n",
    "    #SOacc_all[k,session] = correct/len(ytest)\n",
    "\n",
    "    #balanced accuracy (Source only)\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    SOacc[k] = acc_c/len(np.unique(ytest))\n",
    "\n",
    "    #***SER*** combining source w target data\n",
    "    newRF = SERfuncs.forest_convert(RF)\n",
    "    expRF = SERfuncs.forest_SER(newRF,Xtarget,ytarget,C=5) #refine RF on current data (C is the # of classes on the source)\n",
    "    ypred = np.asarray(map(lambda x:SERfuncs.forest_classify_ensemble(expRF,x),Xtest))\n",
    "    \n",
    "    #correct = sum(ypred == ytest)\n",
    "    #SERacc_all[k,session] = correct/len(ytest)\n",
    "    \n",
    "    #balanced accuracy SER\n",
    "    acc_c = 0\n",
    "    acc_class = np.zeros(5) #the accuracy per class\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    SERacc[k] = acc_c/len(np.unique(ytest))\n",
    "\n",
    "    \n",
    "    #***STRUT*** combining source w target data\n",
    "    STRUT_RF = STRUT(Xtrain,ytrain,Xtarget,ytarget,n_trees=50,verbos = False)\n",
    "    ypred = np.asarray(map(lambda x:forest_classify_ensemble(STRUT_RF,x),Xtest))\n",
    "\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    STRUTacc[k]=acc_c/len(np.unique(ytest))\n",
    "    \n",
    "    #*** MIX ****\n",
    "    #Posteriors from SER and STRUT\n",
    "    ypredMIX = np.empty(len(ytest))\n",
    "    for p in range(len(ytest)):\n",
    "        PSER = SERfuncs.forest_posterior(expRF,Xtest[p]).mean(axis=0)\n",
    "        PSTRUT = SERfuncs.forest_posterior(STRUT_RF,Xtest[p]).mean(axis=0)\n",
    "        PMIX = np.array((PSER,PSTRUT)) \n",
    "        ypredMIX[p] = np.argmax(PMIX.mean(axis=0))\n",
    "        \n",
    "    #balanced accuracy MIX\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypredMIX[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    MIXacc[k]=acc_c/len(np.unique(ytest))\n",
    "    \n",
    "\n",
    "    print 'Test on Patient %s,  '%s\n",
    "    print '# of classes in test = %s'%Nclasses\n",
    "    print 'Source samples = %s, Target samples = %s, Test samples = %s'%(len(ytrain),len(ytarget),len(ytest))\n",
    "    print 'Source Only={:.2f}, Target Only={:.2f}, SER={:.2f}, STRUT={:.2f}, MIX={:.2f}'.format(SOacc[k],TOacc[k],SERacc[k],STRUTacc[k],MIXacc[k])\n",
    "    \n",
    "    k = k+1\n",
    "\n",
    "print '\\nmean Acc - Source only = %s'%SOacc.mean()\n",
    "print 'mean Acc - Target only = %s'%TOacc.mean()\n",
    "print 'mean Acc - SER = %s'%SERacc.mean()\n",
    "print 'mean Acc - STRUT = %s'%STRUTacc.mean()\n",
    "print 'mean Acc - MIX = %s'%MIXacc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43828465,  0.72023703,  0.63862524],\n",
       "       [ 0.37432512,  0.44937952,  0.51200345],\n",
       "       [ 0.48991545,  0.57276063,  0.64186353],\n",
       "       [ 0.5433169 ,  0.64987853,  0.60285796],\n",
       "       [ 0.35844572,  0.75507849,  0.85577584],\n",
       "       [ 0.52180158,  0.49169397,  0.53045469],\n",
       "       [ 0.50376563,  0.45515268,  0.64836612],\n",
       "       [ 0.49598798,  0.84060313,  0.70418798],\n",
       "       [ 0.52788283,  0.58782884,  0.53523815],\n",
       "       [ 0.67723433,  0.8640516 ,  0.84397413]])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((SOacc,TOacc,MIXacc)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13658be10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot([SOacc,TOacc,SERacc,STRUTacc,MIXacc])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x12ddaabd0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEPCAYAAABGP2P1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13658b310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#IG ONLY\n",
    "plt.figure(1)\n",
    "plt.plot(PatientCodes,MIXacc,'ro-',PatientCodes,TOacc,'bo-')\n",
    "plt.xlabel('Patient #')\n",
    "plt.ylabel('Balanced Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train on Source (Healthy) + Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, BAcc = 0.671907981581\n",
      "Patient 2, BAcc = 0.482502667627\n",
      "Patient 5, BAcc = 0.562882500202\n",
      "Patient 6, BAcc = 0.634047174699\n",
      "Patient 8, BAcc = 0.756756949733\n",
      "Patient 11, BAcc = 0.531475746046\n",
      "Patient 14, BAcc = 0.576864733997\n",
      "Patient 15, BAcc = 0.717848903813\n",
      "Patient 16, BAcc = 0.548351901592\n",
      "Patient 19, BAcc = 0.754964349376\n",
      "Mean BAcc using Source + Target = 0.623760290867\n"
     ]
    }
   ],
   "source": [
    "XHealthy = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "yHealthy = HealthyData.select_columns(label_cols).to_numpy()\n",
    "yHealthy = yHealthy.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "SaTacc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 4)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)]\n",
    "    Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "\n",
    "    Xtrain = np.concatenate((XHealthy,Xtarget),axis=0)\n",
    "    ytrain = np.concatenate((yHealthy,ytarget),axis=0)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    SaTacc[k] = BAcc\n",
    "    print 'Patient %s, BAcc = %s'%(s,SaTacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc using Source + Target = %s'%SaTacc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.43828465,  0.72023703,  0.67190798,  0.63862524],\n",
       "       [ 0.37432512,  0.44937952,  0.48250267,  0.51200345],\n",
       "       [ 0.48991545,  0.57276063,  0.5628825 ,  0.64186353],\n",
       "       [ 0.5433169 ,  0.64987853,  0.63404717,  0.60285796],\n",
       "       [ 0.35844572,  0.75507849,  0.75675695,  0.85577584],\n",
       "       [ 0.52180158,  0.49169397,  0.53147575,  0.53045469],\n",
       "       [ 0.50376563,  0.45515268,  0.57686473,  0.64836612],\n",
       "       [ 0.49598798,  0.84060313,  0.7178489 ,  0.70418798],\n",
       "       [ 0.52788283,  0.58782884,  0.5483519 ,  0.53523815],\n",
       "       [ 0.67723433,  0.8640516 ,  0.75496435,  0.84397413]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((SOacc,TOacc,SaTacc,MIXacc)).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Specificity paper tests\n",
    "* Note: Patients currently used are 1 2 5 6 8 11 14 15 16 19\n",
    "* Current paper draft: Sessions 1,2,3 CBR are used for testing, Session 4 CBR as target\n",
    "* **Impairment Specific**: is trained on all but one SCO and tested on the remaining CBR patient\n",
    "* **Patient Specific**: is trained on all SCO data (for that patient) and tested on Sessions 1,2,3 of CBR for the same patients\n",
    "* **Device-Specific**: trained using Leave One Session Out across sessions 1,2,3 of CBR data for that patient. That means the model is trained on Sessions 1,2 and tested on 3 (and then cycles through the combinations). Session 4 was left out for target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PatientCodes = np.array([1, 2, 5, 6, 8, 11, 14, 15, 16, 19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impairment specific model (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Impairment specific (SCO) model - BAcc = 0.507901755815\n",
      "Patient 2, Impairment specific (SCO) model - BAcc = 0.482980771915\n",
      "Patient 5, Impairment specific (SCO) model - BAcc = 0.493355781113\n",
      "Patient 6, Impairment specific (SCO) model - BAcc = 0.5412572619\n",
      "Patient 8, Impairment specific (SCO) model - BAcc = 0.497811415757\n",
      "Patient 11, Impairment specific (SCO) model - BAcc = 0.554825572392\n",
      "Patient 14, Impairment specific (SCO) model - BAcc = 0.582125623729\n",
      "Patient 15, Impairment specific (SCO) model - BAcc = 0.594080790826\n",
      "Patient 16, Impairment specific (SCO) model - BAcc = 0.521982799416\n",
      "Patient 19, Impairment specific (SCO) model - BAcc = 0.887332373509\n",
      "Mean BAcc - Impairment Specific (SCO) = 0.566365414637\n"
     ]
    }
   ],
   "source": [
    "ISpec_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)] #test on 3 CBR sessions\n",
    "    Nclasses = len(train['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    ISpec_acc[k] = BAcc\n",
    "    print 'Patient {}, Impairment specific (SCO) model - BAcc = {:.2f}'.format(s,ISpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Impairment Specific (SCO) = %s'%ISpec_acc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we boost an impairment-specific model with the Device data?\n",
    "Source: Other patients SCO data\n",
    "\n",
    "Target: 1 session of CBR data from current patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:267: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1,  \n",
      "# of classes in test = 5\n",
      "Source samples = 17471, Target samples = 390, Test samples = 1288\n",
      "Source Only=0.51, Target Only=0.72, MIX=0.59\n",
      "Test on Patient 2,  \n",
      "# of classes in test = 5\n",
      "Source samples = 17055, Target samples = 467, Test samples = 991\n",
      "Source Only=0.48, Target Only=0.45, MIX=0.54\n",
      "Test on Patient 5,  \n",
      "# of classes in test = 5\n",
      "Source samples = 16386, Target samples = 415, Test samples = 1358\n",
      "Source Only=0.49, Target Only=0.57, MIX=0.63\n",
      "Test on Patient 6,  \n",
      "# of classes in test = 5\n",
      "Source samples = 17383, Target samples = 881, Test samples = 2035\n",
      "Source Only=0.54, Target Only=0.65, MIX=0.59\n",
      "Test on Patient 8,  \n",
      "# of classes in test = 5\n",
      "Source samples = 16142, Target samples = 354, Test samples = 856\n",
      "Source Only=0.50, Target Only=0.76, MIX=0.79\n",
      "Test on Patient 11,  \n",
      "# of classes in test = 5\n",
      "Source samples = 17131, Target samples = 455, Test samples = 1253\n",
      "Source Only=0.55, Target Only=0.49, MIX=0.57\n",
      "Test on Patient 14,  \n",
      "# of classes in test = 5\n",
      "Source samples = 16787, Target samples = 318, Test samples = 1658\n",
      "Source Only=0.58, Target Only=0.46, MIX=0.60\n",
      "Test on Patient 15,  \n",
      "# of classes in test = 5\n",
      "Source samples = 16899, Target samples = 1605, Test samples = 1906\n",
      "Source Only=0.59, Target Only=0.84, MIX=0.77\n",
      "Test on Patient 16,  \n",
      "# of classes in test = 5\n",
      "Source samples = 16097, Target samples = 608, Test samples = 1126\n",
      "Source Only=0.52, Target Only=0.59, MIX=0.60\n",
      "Test on Patient 19,  \n",
      "# of classes in test = 5\n",
      "Source samples = 17507, Target samples = 545, Test samples = 1020\n",
      "Source Only=0.89, Target Only=0.86, MIX=0.86\n",
      "Mean BAcc - Impairment Specific only = 0.566365414637\n",
      "Mean BAcc - Target only = 0.638666442112\n",
      "Mean BAcc - Impairment Specific w MIX = 0.653873925326\n"
     ]
    }
   ],
   "source": [
    "SOacc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)] #test on 3 CBR sessions\n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 4)] \n",
    "\n",
    "    Nclasses = len(train['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    \n",
    "    #balanced accuracy - Source only (Impairment specific)\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)    \n",
    "    SOacc[k] = acc_c/len(np.unique(ytest))\n",
    "    \n",
    "    #** SER - combining source w target data\n",
    "    newRF = SERfuncs.forest_convert(RF)\n",
    "    expRF = SERfuncs.forest_SER(newRF,Xtarget,ytarget,C=Nclasses) #refine RF on current data (C is the # of classes on the source)\n",
    "    \n",
    "    #***STRUT*** combining source w target data\n",
    "    STRUT_RF = STRUT(Xtrain,ytrain,Xtarget,ytarget,n_trees=50,verbos = False)\n",
    "    ypred = np.asarray(map(lambda x:forest_classify_ensemble(STRUT_RF,x),Xtest))\n",
    "    \n",
    "    #*** MIX ****\n",
    "    #Posteriors from SER and STRUT\n",
    "    ypredMIX = np.empty(len(ytest))\n",
    "    for p in range(len(ytest)):\n",
    "        PSER = SERfuncs.forest_posterior(expRF,Xtest[p]).mean(axis=0)\n",
    "        PSTRUT = SERfuncs.forest_posterior(STRUT_RF,Xtest[p]).mean(axis=0)\n",
    "        PMIX = np.array((PSER,PSTRUT)) \n",
    "        ypredMIX[p] = np.argmax(PMIX.mean(axis=0))\n",
    "        \n",
    "    #balanced accuracy MIX\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypredMIX[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    MIXacc[k]=acc_c/len(np.unique(ytest))\n",
    "    \n",
    "    print 'Test on Patient %s,  '%s\n",
    "    print '# of classes in test = %s'%Nclasses\n",
    "    print 'Source samples = %s, Target samples = %s, Test samples = %s'%(len(ytrain),len(ytarget),len(ytest))\n",
    "    print 'Source Only={:.2f}, Target Only={:.2f}, MIX={:.2f}'.format(SOacc[k],TOacc[k],MIXacc[k])\n",
    "    \n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Impairment Specific only = %s'%SOacc.mean()    \n",
    "print 'Mean BAcc - Target only = %s'%TOacc.mean()    \n",
    "print 'Mean BAcc - Impairment Specific w MIX = %s'%MIXacc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on SCO and test on CBR (Patient Specific model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.72\n",
      "Patient 2, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.55\n",
      "Patient 5, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.65\n",
      "Patient 6, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.58\n",
      "Patient 8, Nclasses = 3, Personal model (Trained on SCO) - BAcc = 0.70\n",
      "Patient 11, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.47\n",
      "Patient 14, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.49\n",
      "Patient 15, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.44\n",
      "Patient 16, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.50\n",
      "Patient 19, Nclasses = 3, Personal model (Trained on SCO) - BAcc = 0.73\n",
      "Mean BAcc - Patient Specific (SCO) = 0.582592163993\n"
     ]
    }
   ],
   "source": [
    "PSpec_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] == s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)]\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    PSpec_acc[k] = BAcc\n",
    "    print 'Patient {}, Nclasses = {}, Personal model (Trained on SCO) - BAcc = {:.2f}'.format(s,Nclasses,PSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Patient Specific (SCO) = %s'%PSpec_acc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train and test on CBR - Device specific model (CBR)\n",
    "* Leave One Session Out of CBR \n",
    "* Keep out 1 session (#4) for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Device Specific model - BAcc = 0.82\n",
      "Patient 2, Device Specific model - BAcc = 0.67\n",
      "Patient 5, Device Specific model - BAcc = 0.64\n",
      "Patient 6, Device Specific model - BAcc = 0.61\n",
      "Patient 8, Device Specific model - BAcc = 0.86\n",
      "Patient 11, Device Specific model - BAcc = 0.69\n",
      "Patient 14, Device Specific model - BAcc = 0.84\n",
      "Patient 15, Device Specific model - BAcc = 0.81\n",
      "Patient 16, Device Specific model - BAcc = 0.70\n",
      "Patient 19, Device Specific model - BAcc = 0.76\n",
      "Mean BAcc - Device Specific (CBR) = 0.740142236182\n"
     ]
    }
   ],
   "source": [
    "DSpec_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    data =  CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)] #keep out 1 session for target\n",
    "    BAcc = 0\n",
    "    for session in range(1,4):\n",
    "                  \n",
    "        test = data[data['Session'] == session]\n",
    "        train = data[data['Session'] != session]\n",
    "    \n",
    "        Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1)\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy\n",
    "        acc_c = 0\n",
    "        for c in np.unique(ytest):\n",
    "            i = ytest == c\n",
    "            correct = ypred[i] == ytest[i]\n",
    "            acc_c += sum(correct)/len(correct)\n",
    "\n",
    "        BAcc += acc_c/len(np.unique(ytest)) #for current session\n",
    "        \n",
    "    DSpec_acc[k] = BAcc/3 #the CV BAcc on 3 session \n",
    "    print 'Patient {}, Device Specific model - BAcc = {:.2f}'.format(s,DSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Device Specific (CBR) = %s'%DSpec_acc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Source: Patient SCO data (4 sessions); Target: Patient CBR data (session 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:267: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1,  \n",
      "# of classes in test = 5\n",
      "Source samples = 1291, Target samples = 390, Test samples = 1288\n",
      "Source Only=0.72, Target Only=0.72, MIX=0.73\n",
      "Test on Patient 2,  \n",
      "# of classes in test = 5\n",
      "Source samples = 1707, Target samples = 467, Test samples = 991\n",
      "Source Only=0.55, Target Only=0.45, MIX=0.51\n",
      "Test on Patient 5,  \n",
      "# of classes in test = 5\n",
      "Source samples = 2376, Target samples = 415, Test samples = 1358\n",
      "Source Only=0.65, Target Only=0.57, MIX=0.65\n",
      "Test on Patient 6,  \n",
      "# of classes in test = 5\n",
      "Source samples = 1379, Target samples = 881, Test samples = 2035\n",
      "Source Only=0.58, Target Only=0.65, MIX=0.66\n",
      "Test on Patient 8,  \n",
      "# of classes in test = 5\n",
      "Source samples = 2620, Target samples = 354, Test samples = 856\n",
      "Source Only=0.70, Target Only=0.76, MIX=0.74\n",
      "Test on Patient 11,  \n",
      "# of classes in test = 5\n",
      "Source samples = 1631, Target samples = 455, Test samples = 1253\n",
      "Source Only=0.47, Target Only=0.49, MIX=0.49\n",
      "Test on Patient 14,  \n",
      "# of classes in test = 5\n",
      "Source samples = 1975, Target samples = 318, Test samples = 1658\n",
      "Source Only=0.49, Target Only=0.46, MIX=0.66\n",
      "Test on Patient 15,  \n",
      "# of classes in test = 5\n",
      "Source samples = 1863, Target samples = 1605, Test samples = 1906\n",
      "Source Only=0.44, Target Only=0.84, MIX=0.71\n",
      "Test on Patient 16,  \n",
      "# of classes in test = 5\n",
      "Source samples = 2665, Target samples = 608, Test samples = 1126\n",
      "Source Only=0.50, Target Only=0.59, MIX=0.59\n",
      "Test on Patient 19,  \n",
      "# of classes in test = 5\n",
      "Source samples = 1255, Target samples = 545, Test samples = 1020\n",
      "Source Only=0.73, Target Only=0.86, MIX=0.78\n",
      "Mean BAcc - Patient Specific only = 0.582592163993\n",
      "Mean BAcc - Target (CBR) only = 0.638666442112\n",
      "Mean BAcc - Patient Specific w MIX = 0.650846949591\n"
     ]
    }
   ],
   "source": [
    "SOacc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] == s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)] #test on 3 CBR sessions\n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 4)] \n",
    "\n",
    "    Nclasses = len(train['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50,random_state=0)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    \n",
    "    #balanced accuracy - Source only (Impairment specific)\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)    \n",
    "    SOacc[k] = acc_c/len(np.unique(ytest))\n",
    "    \n",
    "    #** SER - combining source w target data\n",
    "    newRF = SERfuncs.forest_convert(RF)\n",
    "    expRF = SERfuncs.forest_SER(newRF,Xtarget,ytarget,C=Nclasses) #refine RF on current data (C is the # of classes on the source)\n",
    "    \n",
    "    #***STRUT*** combining source w target data\n",
    "    STRUT_RF = STRUT(Xtrain,ytrain,Xtarget,ytarget,n_trees=50,verbos = False)\n",
    "    ypred = np.asarray(map(lambda x:forest_classify_ensemble(STRUT_RF,x),Xtest))\n",
    "    \n",
    "    #*** MIX ****\n",
    "    #Posteriors from SER and STRUT\n",
    "    ypredMIX = np.empty(len(ytest))\n",
    "    for p in range(len(ytest)):\n",
    "        PSER = SERfuncs.forest_posterior(expRF,Xtest[p]).mean(axis=0)\n",
    "        PSTRUT = SERfuncs.forest_posterior(STRUT_RF,Xtest[p]).mean(axis=0)\n",
    "        PMIX = np.array((PSER,PSTRUT)) \n",
    "        ypredMIX[p] = np.argmax(PMIX.mean(axis=0))\n",
    "        \n",
    "    #balanced accuracy MIX\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypredMIX[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    MIXacc[k]=acc_c/len(np.unique(ytest))\n",
    "    \n",
    "    print 'Test on Patient %s,  '%s\n",
    "    print '# of classes in test = %s'%Nclasses\n",
    "    print 'Source samples = %s, Target samples = %s, Test samples = %s'%(len(ytrain),len(ytarget),len(ytest))\n",
    "    print 'Source Only={:.2f}, Target Only={:.2f}, MIX={:.2f}'.format(SOacc[k],TOacc[k],MIXacc[k])\n",
    "    \n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Patient Specific only = %s'%SOacc.mean()    \n",
    "print 'Mean BAcc - Target (CBR) only = %s'%TOacc.mean()    \n",
    "print 'Mean BAcc - Patient Specific w MIX = %s'%MIXacc.mean()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
