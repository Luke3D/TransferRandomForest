{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import STRUTfuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This non-commercial license of GraphLab Create is assigned to llonini@ricres.org and will expire on November 11, 2016. For commercial licensing options, visit https://turi.com/buy/.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO] graphlab.cython.cy_server: GraphLab Create v2.0.1 started. Logging: /tmp/graphlab_server_1469073014.log\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphlab\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.368497 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.368497 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/HealthyData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 8375 lines in 0.508108 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 8375 lines in 0.508108 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 1.12799 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 1.12799 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientCBRData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 22354 lines in 1.10892 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 22354 lines in 1.10892 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 100 lines in 0.59503 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 100 lines in 0.59503 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------\n",
      "Inferred types from first 100 line(s) of file as \n",
      "column_type_hints=[int,int,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,int,int,int,int,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,float,int]\n",
      "If parsing fails due to incorrect types, you can correct\n",
      "the inferred type list above and pass it to read_csv in\n",
      "the column_type_hints argument\n",
      "------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv</pre>"
      ],
      "text/plain": [
       "Finished parsing file /Users/luca/Projects/Datasets/Cbrace/PatientSCOData.csv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>Parsing completed. Parsed 18762 lines in 0.940608 secs.</pre>"
      ],
      "text/plain": [
       "Parsing completed. Parsed 18762 lines in 0.940608 secs."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HealthyData = graphlab.SFrame.read_csv('../Datasets/Cbrace/HealthyData.csv')\n",
    "CBRData = graphlab.SFrame.read_csv('../Datasets/Cbrace/PatientCBRData.csv')\n",
    "SCOData = graphlab.SFrame.read_csv('../Datasets/Cbrace/PatientSCOData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\"><table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">SubjID</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Session</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  1</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  2</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  3</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  4</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  5</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  6</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.051382320442</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.6076</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.196</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0253933701657</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.6076</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1176</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">178</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0248519337017</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.49</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1176</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0465635359116</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.3136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">181</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0781834254144</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.2352</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">56</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  8</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_  9</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 10</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 11</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 12</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.112454267826</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.294668590342</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">2.38556796968</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.000653333333333</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.072657333349</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.181289226345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0983200079119</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0523105353163</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.41100727695</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.000435555555556</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0780695955254</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.180121837472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0841222692085</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.592549758023</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.41421963842</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000653333333333</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0698793552525</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.24648779524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0654386480834</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-1.01056633159</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.65404790008</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000217777777778</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0504932952633</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.225561487781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0375305142722</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.712656990085</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.19196004385</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000217777777778</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0415385735192</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.130183600125</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 14</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 15</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 16</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 17</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 18</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 19</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 20</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.849714754</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.08929834254</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.7644</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.539</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.89013448447</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6.99232707182</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.7644</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1568</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.91346159405</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">6.98496353591</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.49</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.1176</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.15285973332</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.01284751381</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.3136</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0392</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.15415404049</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.03970276243</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.2352</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 22</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 23</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 24</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 25</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 26</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.252559348905</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.441806399998</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.50225147456</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.00234111111111</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0614360391284</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.350425643783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.163775773499</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.35066706204</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.8748955425</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.00190555555556</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0682046491004</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.272877559768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0861118742405</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.935385885979</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.09906709893</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.061650817028</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.00567046879142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0628676683988</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.924831026921</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.34203744561</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000653333333333</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.048583233193</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.20819575962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0370766090247</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.613014026838</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.89219892908</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.000217777777778</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0429608801596</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.164208050896</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 28</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 29</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 30</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 31</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 32</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 33</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 34</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 35</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.98909461353</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.27022541436</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8428</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.4606</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.35673213621</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.34927513812</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.8428</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.147</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.06132460327</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.35820883978</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.735</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0784</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.52215990866</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.33557679558</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.343</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0392</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">3.73771975026</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">8.31483977901</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.2254</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0</td>\n",
       "    </tr>\n",
       "</table>\n",
       "<table frame=\"box\" rules=\"cols\">\n",
       "    <tr>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 36</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 37</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">Features_ 38</th>\n",
       "        <th style=\"padding-left: 1em; padding-right: 1em; text-align: center\">...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.219706356595</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.127990349631</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.71927560428</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.155590412767</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">-0.639652012448</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.13275290921</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0925837130462</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.03393366067</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">7.73592612692</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0506722377716</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">1.05044494342</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">4.46466722648</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.0292622124165</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">0.282918434936</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">5.74073784939</td>\n",
       "        <td style=\"padding-left: 1em; padding-right: 1em; text-align: center; vertical-align: top\">...</td>\n",
       "    </tr>\n",
       "</table>\n",
       "[5 rows x 134 columns]<br/>\n",
       "</div>"
      ],
      "text/plain": [
       "Columns:\n",
       "\tSubjID\tint\n",
       "\tSession\tint\n",
       "\tFeatures_  1\tfloat\n",
       "\tFeatures_  2\tfloat\n",
       "\tFeatures_  3\tfloat\n",
       "\tFeatures_  4\tint\n",
       "\tFeatures_  5\tint\n",
       "\tFeatures_  6\tint\n",
       "\tFeatures_  7\tint\n",
       "\tFeatures_  8\tfloat\n",
       "\tFeatures_  9\tfloat\n",
       "\tFeatures_ 10\tfloat\n",
       "\tFeatures_ 11\tfloat\n",
       "\tFeatures_ 12\tfloat\n",
       "\tFeatures_ 13\tfloat\n",
       "\tFeatures_ 14\tfloat\n",
       "\tFeatures_ 15\tfloat\n",
       "\tFeatures_ 16\tfloat\n",
       "\tFeatures_ 17\tfloat\n",
       "\tFeatures_ 18\tint\n",
       "\tFeatures_ 19\tint\n",
       "\tFeatures_ 20\tint\n",
       "\tFeatures_ 21\tint\n",
       "\tFeatures_ 22\tfloat\n",
       "\tFeatures_ 23\tfloat\n",
       "\tFeatures_ 24\tfloat\n",
       "\tFeatures_ 25\tfloat\n",
       "\tFeatures_ 26\tfloat\n",
       "\tFeatures_ 27\tfloat\n",
       "\tFeatures_ 28\tfloat\n",
       "\tFeatures_ 29\tfloat\n",
       "\tFeatures_ 30\tfloat\n",
       "\tFeatures_ 31\tfloat\n",
       "\tFeatures_ 32\tint\n",
       "\tFeatures_ 33\tint\n",
       "\tFeatures_ 34\tint\n",
       "\tFeatures_ 35\tint\n",
       "\tFeatures_ 36\tfloat\n",
       "\tFeatures_ 37\tfloat\n",
       "\tFeatures_ 38\tfloat\n",
       "\tFeatures_ 39\tfloat\n",
       "\tFeatures_ 40\tfloat\n",
       "\tFeatures_ 41\tfloat\n",
       "\tFeatures_ 42\tfloat\n",
       "\tFeatures_ 43\tfloat\n",
       "\tFeatures_ 44\tfloat\n",
       "\tFeatures_ 45\tfloat\n",
       "\tFeatures_ 46\tfloat\n",
       "\tFeatures_ 47\tfloat\n",
       "\tFeatures_ 48\tfloat\n",
       "\tFeatures_ 49\tfloat\n",
       "\tFeatures_ 50\tfloat\n",
       "\tFeatures_ 51\tfloat\n",
       "\tFeatures_ 52\tfloat\n",
       "\tFeatures_ 53\tfloat\n",
       "\tFeatures_ 54\tfloat\n",
       "\tFeatures_ 55\tfloat\n",
       "\tFeatures_ 56\tfloat\n",
       "\tFeatures_ 57\tfloat\n",
       "\tFeatures_ 58\tfloat\n",
       "\tFeatures_ 59\tfloat\n",
       "\tFeatures_ 60\tfloat\n",
       "\tFeatures_ 61\tfloat\n",
       "\tFeatures_ 62\tfloat\n",
       "\tFeatures_ 63\tfloat\n",
       "\tFeatures_ 64\tfloat\n",
       "\tFeatures_ 65\tfloat\n",
       "\tFeatures_ 66\tfloat\n",
       "\tFeatures_ 67\tfloat\n",
       "\tFeatures_ 68\tfloat\n",
       "\tFeatures_ 69\tfloat\n",
       "\tFeatures_ 70\tfloat\n",
       "\tFeatures_ 71\tfloat\n",
       "\tFeatures_ 72\tfloat\n",
       "\tFeatures_ 73\tfloat\n",
       "\tFeatures_ 74\tfloat\n",
       "\tFeatures_ 75\tfloat\n",
       "\tFeatures_ 76\tfloat\n",
       "\tFeatures_ 77\tfloat\n",
       "\tFeatures_ 78\tfloat\n",
       "\tFeatures_ 79\tfloat\n",
       "\tFeatures_ 80\tfloat\n",
       "\tFeatures_ 81\tfloat\n",
       "\tFeatures_ 82\tfloat\n",
       "\tFeatures_ 83\tfloat\n",
       "\tFeatures_ 84\tfloat\n",
       "\tFeatures_ 85\tfloat\n",
       "\tFeatures_ 86\tfloat\n",
       "\tFeatures_ 87\tfloat\n",
       "\tFeatures_ 88\tfloat\n",
       "\tFeatures_ 89\tfloat\n",
       "\tFeatures_ 90\tfloat\n",
       "\tFeatures_ 91\tfloat\n",
       "\tFeatures_ 92\tfloat\n",
       "\tFeatures_ 93\tfloat\n",
       "\tFeatures_ 94\tfloat\n",
       "\tFeatures_ 95\tfloat\n",
       "\tFeatures_ 96\tfloat\n",
       "\tFeatures_ 97\tfloat\n",
       "\tFeatures_ 98\tfloat\n",
       "\tFeatures_ 99\tfloat\n",
       "\tFeatures_100\tfloat\n",
       "\tFeatures_101\tfloat\n",
       "\tFeatures_102\tfloat\n",
       "\tFeatures_103\tfloat\n",
       "\tFeatures_104\tfloat\n",
       "\tFeatures_105\tfloat\n",
       "\tFeatures_106\tfloat\n",
       "\tFeatures_107\tfloat\n",
       "\tFeatures_108\tfloat\n",
       "\tFeatures_109\tfloat\n",
       "\tFeatures_110\tfloat\n",
       "\tFeatures_111\tfloat\n",
       "\tFeatures_112\tfloat\n",
       "\tFeatures_113\tfloat\n",
       "\tFeatures_114\tfloat\n",
       "\tFeatures_115\tfloat\n",
       "\tFeatures_116\tfloat\n",
       "\tFeatures_117\tfloat\n",
       "\tFeatures_118\tfloat\n",
       "\tFeatures_119\tfloat\n",
       "\tFeatures_120\tfloat\n",
       "\tFeatures_121\tfloat\n",
       "\tFeatures_122\tfloat\n",
       "\tFeatures_123\tfloat\n",
       "\tFeatures_124\tfloat\n",
       "\tFeatures_125\tfloat\n",
       "\tFeatures_126\tfloat\n",
       "\tFeatures_127\tfloat\n",
       "\tFeatures_128\tfloat\n",
       "\tFeatures_129\tfloat\n",
       "\tFeatures_130\tfloat\n",
       "\tFeatures_131\tfloat\n",
       "\tLabel\tint\n",
       "\n",
       "Rows: 5\n",
       "\n",
       "Data:\n",
       "+--------+---------+-----------------+--------------+--------------+--------------+\n",
       "| SubjID | Session |   Features_  1  | Features_  2 | Features_  3 | Features_  4 |\n",
       "+--------+---------+-----------------+--------------+--------------+--------------+\n",
       "|   1    |    1    |  0.051382320442 |    0.6076    |    0.196     |      0       |\n",
       "|   1    |    1    | 0.0253933701657 |    0.6076    |    0.1176    |      0       |\n",
       "|   1    |    1    | 0.0248519337017 |     0.49     |    0.1176    |      0       |\n",
       "|   1    |    1    | 0.0465635359116 |    0.3136    |    0.0784    |      0       |\n",
       "|   1    |    1    | 0.0781834254144 |    0.2352    |    0.0784    |      56      |\n",
       "+--------+---------+-----------------+--------------+--------------+--------------+\n",
       "+--------------+--------------+--------------+-----------------+-----------------+\n",
       "| Features_  5 | Features_  6 | Features_  7 |   Features_  8  |   Features_  9  |\n",
       "+--------------+--------------+--------------+-----------------+-----------------+\n",
       "|     181      |      0       |      0       |  0.112454267826 | -0.294668590342 |\n",
       "|     178      |      3       |      0       | 0.0983200079119 | 0.0523105353163 |\n",
       "|     181      |      0       |      0       | 0.0841222692085 | -0.592549758023 |\n",
       "|     181      |      0       |      0       | 0.0654386480834 |  -1.01056633159 |\n",
       "|      0       |      0       |      0       | 0.0375305142722 | -0.712656990085 |\n",
       "+--------------+--------------+--------------+-----------------+-----------------+\n",
       "+---------------+--------------------+-----------------+----------------+\n",
       "|  Features_ 10 |    Features_ 11    |   Features_ 12  |  Features_ 13  |\n",
       "+---------------+--------------------+-----------------+----------------+\n",
       "| 2.38556796968 | -0.000653333333333 |  0.072657333349 | 0.181289226345 |\n",
       "| 3.41100727695 | -0.000435555555556 | 0.0780695955254 | 0.180121837472 |\n",
       "| 3.41421963842 | 0.000653333333333  | 0.0698793552525 | 0.24648779524  |\n",
       "| 3.65404790008 | 0.000217777777778  | 0.0504932952633 | 0.225561487781 |\n",
       "| 4.19196004385 | 0.000217777777778  | 0.0415385735192 | 0.130183600125 |\n",
       "+---------------+--------------------+-----------------+----------------+\n",
       "+---------------+---------------+--------------+--------------+--------------+-----+\n",
       "|  Features_ 14 |  Features_ 15 | Features_ 16 | Features_ 17 | Features_ 18 | ... |\n",
       "+---------------+---------------+--------------+--------------+--------------+-----+\n",
       "|  4.849714754  | 7.08929834254 |    0.7644    |    0.539     |      0       | ... |\n",
       "| 3.89013448447 | 6.99232707182 |    0.7644    |    0.1568    |      0       | ... |\n",
       "| 4.91346159405 | 6.98496353591 |     0.49     |    0.1176    |      0       | ... |\n",
       "| 4.15285973332 | 7.01284751381 |    0.3136    |    0.0392    |      0       | ... |\n",
       "| 4.15415404049 | 7.03970276243 |    0.2352    |    0.0784    |      0       | ... |\n",
       "+---------------+---------------+--------------+--------------+--------------+-----+\n",
       "[5 rows x 134 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CBRData.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61]\n",
      "[1, 2, 5, 6, 8, 11, 12, 13, 14, 15, 16, 19]\n"
     ]
    }
   ],
   "source": [
    "#SUBJECTS IN THE DATABASE\n",
    "HealthyCodes = HealthyData['SubjID'].unique()\n",
    "HealthyCodes = HealthyCodes.sort()\n",
    "print HealthyCodes\n",
    "PatientCodes = CBRData['SubjID'].unique()\n",
    "PatientCodes = PatientCodes.sort()\n",
    "print PatientCodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Most of the errors come from sitting being confounded with standing and viceversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Healthy and test on CBR patients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from math import log\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def convert_from_scikit_learn_to_dic_ite(node_index,is_leaves, children_left,children_right,feature,threshold,value,labels,C):\n",
    "        \n",
    "        a = is_leaves[0]\n",
    "        b = feature[0]\n",
    "        c = threshold[0]\n",
    "        if (a):\n",
    "            d = value[0]  #datapoints of each class in the node\n",
    "            d2 = np.squeeze(d/np.sum(d))\n",
    "            d3 = np.zeros(C)\n",
    "            d3[labels] = d2\n",
    "            e = labels[np.argmax(d2)]\n",
    "            return {'splitting_feature' : None,\n",
    "            'left' : None,\n",
    "            'right' : None,\n",
    "            'is_leaf': True,\n",
    "            'prediction': e,\n",
    "            'labels_distribution':d3}\n",
    "    \n",
    "        else:\n",
    "            left = children_left[0]-node_index[0]\n",
    "            if(left==-1):\n",
    "                left_tree = None\n",
    "            else:\n",
    "                left = int(left)\n",
    "                left_tree = convert_from_scikit_learn_to_dic_ite(node_index[left:],is_leaves[left:], children_left[left:],children_right[left:],feature[left:],threshold[left:],value[left:],labels,C)\n",
    "            right = children_right[0]-node_index[0]\n",
    "            if(right==-1):\n",
    "                right_tree = None\n",
    "            else:\n",
    "                right = int(right)\n",
    "                right_tree = convert_from_scikit_learn_to_dic_ite(node_index[right:],is_leaves[right:], children_left[right:],children_right[right:],feature[right:],threshold[right:],value[right:],labels,C)\n",
    "            return {'is_leaf'          : False, \n",
    "            'prediction'       : None,\n",
    "            'splitting_feature': b,\n",
    "            'threshold'        : c,\n",
    "            'left'             : left_tree, \n",
    "            'right'            : right_tree,\n",
    "            'labels_distribution': None}\n",
    "\n",
    "\n",
    "def convert_from_scikit_learn_to_dic_STRUT(tree,threshold,C,Q,target_lf,target_lr,feature):\n",
    "    # C is the size of the whole labels\n",
    "    # labels are the labels that are used in the this tree\n",
    "    labels = range(0,C,1)\n",
    "    #n_nodes = tree.tree_.node_count\n",
    "    n_nodes = target_lr.shape[0]\n",
    "    children_left = target_lf\n",
    "    children_right = target_lr\n",
    "    #feature = tree.tree_.feature\n",
    "    node_index = np.array(range(0,n_nodes))\n",
    "    Val = Q   #datapoints in node\n",
    "# The tree structure can be traversed to compute various properties such\n",
    "# as the depth of each node and whether or not it is a leaf.\n",
    "    node_depth = np.zeros(shape=n_nodes)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, -1)]  # seed is the root node id and its parent depth\n",
    "    while len(stack) > 0:\n",
    "        node_id, parent_depth = stack.pop()\n",
    "        node_depth[node_id] = parent_depth + 1\n",
    "    # If we have a test node\n",
    "        if (children_left[node_id] != children_right[node_id]):\n",
    "            stack.append((children_left[node_id], parent_depth + 1))\n",
    "            stack.append((children_right[node_id], parent_depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "    \n",
    "    return convert_from_scikit_learn_to_dic_ite(node_index,is_leaves, children_left,children_right,feature,threshold,Val,labels,C)\n",
    "\n",
    "def TransferToSKLsequence(ch_left,ch_right,subset):\n",
    "    new_left = np.zeros(len(subset))\n",
    "    new_right = np.zeros(len(subset))\n",
    "    for i in range(len(subset)):\n",
    "        (I,) = np.where(subset == ch_left[subset[i]])\n",
    "        if len(I)==0:\n",
    "            new_left[i] = -1\n",
    "        else:\n",
    "            \n",
    "            new_left[i] = I\n",
    "            \n",
    "        (I,) = np.where(subset == ch_right[subset[i]])\n",
    "        if len(I)==0:\n",
    "            new_right[i] = -1\n",
    "        else:\n",
    "            new_right[i] = I\n",
    "    return (new_left,new_right)\n",
    "\n",
    "def kl (p,q): # Kullback-libler divegence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)+.0001\n",
    "    return np.sum(np.where(p != 0,p * np.log10((p / q)), 0))\n",
    "\n",
    "def jsd(p,q): # Symmetric Kullback-libler divergence\n",
    "    p = np.asarray(p, dtype=np.float)\n",
    "    q = np.asarray(q, dtype=np.float)\n",
    "    m = (p+q)/2\n",
    "    return (kl(p,m)+kl(m,q))/2\n",
    "\n",
    "def infogain(yleft,len_left,yright,len_right):\n",
    "    yparent = (yleft+yright)/2\n",
    "    N = len_left+len_right\n",
    "    #compute information gain\n",
    "    I = entropy(yparent) -( (len_left/N)*entropy(yleft) + (len_right/N)*entropy(yright) )   \n",
    "    return I\n",
    "\n",
    "#entropy for multiple classes\n",
    "def entropy(y):\n",
    "    y1 = y[y!=0]\n",
    "    H = -(y1*np.log10(y1)).sum()\n",
    "    return H \n",
    "\n",
    "def partition(Xtarget,ytarget,index_of_data,feature,C,threshold): # divide the data to the left and rightbased on the threshold\n",
    "    left = index_of_data[Xtarget[index_of_data,feature]<threshold]\n",
    "    if(len(left)==0):\n",
    "        left = index_of_data[Xtarget[index_of_data,feature]<=threshold]\n",
    "    labels_left = ytarget[left]\n",
    "    qL = np.bincount(labels_left)\n",
    "    right = index_of_data[Xtarget[index_of_data,feature]>=threshold]\n",
    "    labels_right = ytarget[right]\n",
    "    qR = np.bincount(labels_right)\n",
    "    qR = np.append(qR,np.zeros(np.max([C-qR.shape[0],0])))\n",
    "    qL = np.append(qL,np.zeros(np.max([C-qL.shape[0],0]))) \n",
    "    qL = qL/qL.sum()\n",
    "    qR = qR/qR.sum()\n",
    "    return [qL,left,qR,right]\n",
    "\n",
    "def dg(Sleft,lenleft,Sright,lenright,QL,QR): # DG function as in the paper    \n",
    "    return 1-(lenleft/(lenleft+lenright))*jsd(Sleft,QL)-(lenright/(lenleft+lenright))*jsd(Sright,QR)\n",
    "    \n",
    "def threshold_selection(X,y,S,f,QL,QR,C,verbos): # finding the best threshold\n",
    "    fvals = np.sort(X[S,f])\n",
    "    num_data_points = len(fvals)\n",
    "    N = 10\n",
    "    Val  = np.array([])\n",
    "    #Val_swap  = np.array([])\n",
    "    Val_infogain = np.array([])\n",
    "    if num_data_points > N-1: \n",
    "        I = range(0,num_data_points,np.floor(num_data_points/N).astype(int))\n",
    "        fvals = fvals[I[1:-1]]\n",
    "    for i in fvals: #looping through the thresholds\n",
    "        [Sleft, left, Sright, right] = partition(X,y,S,f,C,i) #find splits based on threshold\n",
    "        \n",
    "        #fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex='col', sharey='row')\n",
    "        #ax1.plot(QL)\n",
    "        #ax1.set_title('QL')\n",
    "        #ax2.plot(Sleft, color='r')\n",
    "        #ax2.set_title('QprimeL')\n",
    "        #ax3.plot(QR)\n",
    "        #ax3.set_title('QR')\n",
    "        #ax4.plot(Sright, color='r')\n",
    "        #ax4.set_title('QprimeR')\n",
    "        Val = np.append(Val,dg(Sleft,len(left),Sright,len(right),QL,QR)) # Here we compute DG between the source dist and target\n",
    "        #print 'DG = %s' %Val[-1]\n",
    "        #print 'QL=%s, QR=%s, Sleft=%s, Sright=%s' %(QL,QR,Sleft,Sright)\n",
    "        Val_infogain = np.append(Val_infogain,infogain(Sleft,len(left),Sright,len(right))) #Compute IG\n",
    "        #Val_swap = np.append(Val_swap,dg(Sleft,len(left),Sright,len(right),QR,QL)) # this is the divergence measure for each threshold split  \n",
    "    if(verbos):\n",
    "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, sharex='col', sharey='row')\n",
    "    #ax1.plot(Val)\n",
    "    #ax1.set_title('DG')\n",
    "    #ax2.plot(Val_infogain)\n",
    "    #ax2.set_title('infogain')\n",
    "        ax1.plot(fvals,Val,'r')\n",
    "        ax1.hold(True)\n",
    "        ax1.plot(fvals,Val_infogain)\n",
    "        ax1.hold(False)\n",
    "        ax1.set_title('DG and Infogain')\n",
    "    #plt.show()\n",
    "    Val[np.isnan(Val)] = min(Val[~np.isnan(Val)])\n",
    "    Val_infogain[np.isnan(Val_infogain)] = min(Val_infogain[~np.isnan(Val_infogain)])\n",
    "    #Val_swap[np.isnan(Val_swap)] = min(Val_swap[~np.isnan(Val_swap)])\n",
    "    th = fvals[np.argmax(Val)] #Maximizing threshold for DG\n",
    "    th_infogain = fvals[np.argmax(Val_infogain)]\n",
    "    if(len(S)<50):\n",
    "        [ql, left, qr, right] = partition(X,y,S,f,C,th_infogain)\n",
    "    else:\n",
    "        [ql, left, qr, right] = partition(X,y,S,f,C,th)\n",
    "    if(verbos):\n",
    "        ax2.plot(ql)\n",
    "        ax2.hold(True)\n",
    "        ax2.plot(qr)\n",
    "        ax2.hold(False)\n",
    "        ax2.set_title('Dist Target Data')\n",
    "\n",
    "        ax3.plot(QL)\n",
    "        ax3.hold(True)\n",
    "        ax3.plot(QR)\n",
    "        ax3.hold(False)\n",
    "        ax3.set_title('Dist Source Data')\n",
    "    #print Val\n",
    "    return [th, ql, qr, left, right]\n",
    "\n",
    "def classify(tree, x):   \n",
    "    # if the node is a leaf node.\n",
    "    if tree['is_leaf']:\n",
    "        return tree['labels_distribution'] \n",
    "    else:\n",
    "        # split on feature.\n",
    "        val_split_feature = x[tree['splitting_feature']]\n",
    "        if val_split_feature < tree['threshold']:\n",
    "            return classify(tree['left'], x)\n",
    "        else:\n",
    "            return classify(tree['right'],x)\n",
    "\n",
    "def forest_posterior(RF,x):\n",
    "\n",
    "    T = len(RF)  #the number of trees \n",
    "\n",
    "    #infer the number of classes\n",
    "    P0 = classify(RF[0],x)\n",
    "    C = len(P0)\n",
    "    \n",
    "    Pt = np.zeros((T,C)) #matrix of posteriors from each tree (T x Nclasses)\n",
    "    Pt[0,:] = P0\n",
    "    for t in range(len(RF))[1:]:\n",
    "        Pt[t,:] = classify(RF[t],x) \n",
    "    return Pt\n",
    "\n",
    "#classify input based on majority voting of each tree prediction\n",
    "def forest_classify_majority(RF,x):\n",
    "        Pt = forest_posterior(RF,x)\n",
    "        Yt = np.argmax(Pt,axis=1)         \n",
    "        C,unique_counts = np.unique(Yt,return_counts=True) #the id of classes and number of each\n",
    "        return C[np.argmax(unique_counts)]   \n",
    "    \n",
    "#classify input by averaging posteriors \n",
    "def forest_classify_ensemble(RF,x):\n",
    "    Pt = forest_posterior(RF,x)\n",
    "    Pforest = Pt.mean(axis=0)\n",
    "    ypred = np.argmax(Pt.mean(axis=0))\n",
    "    return ypred\n",
    "\n",
    "def evaluate_classification_error(RF, X, y, method = None):  \n",
    "    # Apply the forest_classify(RF, x) to each row in your data\n",
    "    if method == None:\n",
    "        ypred = map(lambda x: forest_classify_ensemble(RF,x), X)\n",
    "        # Once you've made the predictions, calculate the classification error and return it\n",
    "        mistakes = sum(ypred != y)\n",
    "        error = mistakes/len(y)\n",
    "    return error\n",
    "\n",
    "def value_for_all(estimator,N):\n",
    "    from scipy.sparse import csr_matrix\n",
    "    ch_left = estimator.tree_.children_left\n",
    "    ch_right = estimator.tree_.children_right\n",
    "    (cl,) = np.where(ch_left!=-1)\n",
    "    (cr,) = np.where(ch_right!=-1)\n",
    "    cap = estimator.tree_.capacity\n",
    "    dis_node = np.zeros((cap,estimator.tree_.n_classes))\n",
    "    A = np.zeros([cap,cap])\n",
    "    D = A\n",
    "    A = csr_matrix(A)\n",
    "    A[cl,ch_left[cl]] = 1\n",
    "    A[cr,ch_right[cr]] = 1\n",
    "    B = A\n",
    "    C = B\n",
    "    while(C.sum()!=0):\n",
    "        C = A*C\n",
    "        B = B + C\n",
    "    I,J = B.nonzero()\n",
    "    D[I,J] = 1\n",
    "    (I,) = np.where(ch_left==-1)\n",
    "    dis_node[I,:] = np.squeeze(estimator.tree_.value[I])\n",
    "    for i in I:\n",
    "        dis_node[i,:] = dis_node[i,:]/dis_node[i,:].sum()\n",
    "    (remain1,) = np.where(ch_left!=-1)\n",
    "    for i in remain1:\n",
    "        (I,) = np.where(D[i,:]==1)\n",
    "        dis_node[i,:] = np.sum(np.squeeze(estimator.tree_.value[I]),axis = 0)\n",
    "        dis_node[i,:] = dis_node[i,:]/dis_node[i,:].sum()\n",
    "    Dis_node = np.zeros((cap,N))\n",
    "    Dis_node[:,estimator.classes_.astype(int)] = dis_node\n",
    "    return Dis_node\n",
    "    \n",
    "def STRUCT(Xsource,ysource,Xtarget,ytarget,n_trees,C,verbos = False):\n",
    "    # Assumption: ysource has all the labels of the problem \n",
    "    #estimator = DecisionTreeClassifier(max_features='sqrt',random_state=0,max_depth=2)\n",
    "    Estimator = RandomForestClassifier(max_features='sqrt',random_state=0,n_estimators=n_trees)\n",
    "    Estimator = Estimator.fit(Xsource, ysource)\n",
    "    RF = []\n",
    "    for rf in range(Estimator.n_estimators):\n",
    "        estimator = Estimator.estimators_[rf]\n",
    "        dis_node = value_for_all(estimator,C)\n",
    "        P = list(np.zeros(estimator.tree_.capacity))\n",
    "        P[0] = range(len(ytarget))\n",
    "        Q = list(np.zeros(estimator.tree_.capacity))\n",
    "        Q[0] = dis_node[0,:]\n",
    "        thresh = np.zeros(estimator.tree_.capacity)\n",
    "        remain = [0]\n",
    "        subset = []\n",
    "        while(len(remain)!=0):\n",
    "            i = remain[0]\n",
    "            LF = estimator.tree_.children_left\n",
    "            LR = estimator.tree_.children_right\n",
    "            index_left = LF[i]\n",
    "            index_right = LR[i]\n",
    "            if(index_left!=-1):\n",
    "                QL = dis_node[index_left,:]\n",
    "                QR = dis_node[index_right,:]\n",
    "                f = estimator.tree_.feature[i]\n",
    "                [th, ql, qr, left, right] = threshold_selection(Xtarget,ytarget,np.array(P[i]),f,QL,QR,C,verbos)\n",
    "                thresh[i] = th\n",
    "                P[index_left] = left\n",
    "                P[index_right] = right\n",
    "                Q[index_left] = ql\n",
    "                Q[index_right] = qr\n",
    "                if(len(left)!=0):\n",
    "                    remain = np.append(remain,index_left)\n",
    "                if(len(right)!=0):\n",
    "                    remain = np.append(remain,index_right)\n",
    "                if(len(left)>0 and len(right)>0):\n",
    "                    subset.append(i)\n",
    "            remain = remain[1:]\n",
    "        lf =  LF[subset]\n",
    "        lr =  LR[subset]\n",
    "        subset = np.append(subset,lf)\n",
    "        subset = np.append(subset,lr)\n",
    "        subset = np.unique(np.sort(subset))\n",
    "        subset = np.array(subset)\n",
    "        (target_lf,target_lr) = TransferToSKLsequence(np.array(LF),np.array(LR),subset)\n",
    "        ST = convert_from_scikit_learn_to_dic_STRUT(estimator,thresh,C,Q,target_lf,target_lr,estimator.tree_.feature[subset])\n",
    "        RF.append(ST)\n",
    "    return RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1\n",
      "Train samples = 8375, Test samples = 1177\n",
      "BAcc = 0.383916382907\n",
      "Test on Patient 2\n",
      "Train samples = 8375, Test samples = 1228\n",
      "BAcc = 0.321884511072\n",
      "Test on Patient 5\n",
      "Train samples = 8375, Test samples = 1468\n",
      "BAcc = 0.428088587201\n",
      "Test on Patient 6\n",
      "Train samples = 8375, Test samples = 2246\n",
      "BAcc = 0.605924879857\n",
      "Test on Patient 8\n",
      "Train samples = 8375, Test samples = 926\n",
      "BAcc = 0.294756143737\n",
      "Test on Patient 11\n",
      "Train samples = 8375, Test samples = 1207\n",
      "BAcc = 0.453916872403\n",
      "Test on Patient 14\n",
      "Train samples = 8375, Test samples = 1527\n",
      "BAcc = 0.47469576857\n",
      "Test on Patient 15\n",
      "Train samples = 8375, Test samples = 3177\n",
      "BAcc = 0.467329935949\n",
      "Test on Patient 16\n",
      "Train samples = 8375, Test samples = 1354\n",
      "BAcc = 0.665314940863\n",
      "Test on Patient 19\n",
      "Train samples = 8375, Test samples = 1328\n",
      "BAcc = 0.560226171326\n",
      "\n",
      "mean acc Source only = 0.465605419388\n"
     ]
    }
   ],
   "source": [
    "col_names = HealthyData.column_names()\n",
    "label_cols = col_names[-1:] #the : is used to return a list with one element \n",
    "feature_cols = col_names[2:-1]\n",
    "\n",
    "Xtrain = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "ytrain = HealthyData.select_columns(label_cols).to_numpy()\n",
    "ytrain = ytrain.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=10)\n",
    "RF = RF.fit(Xtrain,ytrain)\n",
    "\n",
    "#test on each patient (CBR)\n",
    "#PatientCodes = CBRData['SubjID'].unique()\n",
    "#PatientCodes = PatientCodes.sort()\n",
    "PatientCodes = np.array([1, 2, 5, 6, 8, 11, 14, 15, 16, 19]) #all patient with 4 sessions in CBR \n",
    "SOacc = np.zeros(len(PatientCodes))\n",
    "k = 0\n",
    "\n",
    "for s in PatientCodes:\n",
    "    test = CBRData[(CBRData['SubjID'] == s)  & (CBRData['Session'] != 1)] #keep out one session (used later for target)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "\n",
    "    print 'Test on Patient %s'%s\n",
    "    print 'Train samples = %s, Test samples = %s'%(len(ytrain),len(ytest))\n",
    "    ypred = RF.predict(Xtest)\n",
    "\n",
    "    #    acc = sum(ypred == ytest)\n",
    "    #    CVacc[k] = acc/len(ytest)\n",
    "\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    SOacc[k] = BAcc\n",
    "\n",
    "    print 'BAcc = %s'%SOacc[k]\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmean acc Source only = %s'%SOacc.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now test the STRUT - Use one session of data from each patient as target and the remaining as his test\n",
    "* Need to compute CV error on each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on Patient 1,  \n",
      "# of classes = 5\n",
      "Source samples = 8375, Target samples = 501, Test samples = 1177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:255: DeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/scipy/sparse/compressed.py:730: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/matplotlib/pyplot.py:516: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:66: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:68: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:69: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:70: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/Users/luca/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:72: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Profile printout saved to text file u'SpeedStrut.txt'. \n",
      "Accuracy w STRUT = 0.627240110399\n",
      "\n",
      "Test on Patient 2,  \n",
      "# of classes = 5\n",
      "Source samples = 8375, Target samples = 230, Test samples = 1228\n",
      "Accuracy w STRUT = 0.418331987806\n",
      "\n",
      "Test on Patient 5,  \n",
      "# of classes = 5\n",
      "Source samples = 8375, Target samples = 305, Test samples = 1468\n",
      "Accuracy w STRUT = 0.4928639829\n",
      "\n",
      "Test on Patient 6,  \n",
      "# of classes = 4\n",
      "Source samples = 8375, Target samples = 670, Test samples = 2246\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 1 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-ee3c35d34539>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'lprun -s -f STRUCT -T SpeedStrut.txt STRUCT(Xtrain,ytrain,Xtarget,ytarget,n_trees=10,C=Nclasses,verbos = True)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mSTRUT_RF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSTRUCT\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mytarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m#balanced accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7dec4a7c6a43>\u001b[0m in \u001b[0;36mSTRUCT\u001b[0;34m(Xsource, ysource, Xtarget, ytarget, n_trees, C, verbos)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEstimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         \u001b[0mdis_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_for_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mP\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapacity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mP\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mytarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-7dec4a7c6a43>\u001b[0m in \u001b[0;36mvalue_for_all\u001b[0;34m(estimator, N)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mdis_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdis_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0mDis_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m     \u001b[0mDis_node\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdis_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mDis_node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4 is out of bounds for axis 1 with size 4"
     ]
    }
   ],
   "source": [
    "SOacc = np.zeros(len(PatientCodes)) #to store err when using source only\n",
    "STRUTacc = np.zeros(len(PatientCodes)) #to store err when using source + Target with STRUT\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "\n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 1)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 1)]\n",
    "    Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "\n",
    "    print 'Test on Patient %s,  '%s\n",
    "    print '# of classes = %s'%Nclasses\n",
    "    print 'Source samples = %s, Target samples = %s, Test samples = %s'%(len(ytrain),len(ytarget),len(ytest))\n",
    "\n",
    "    #train forest using STRUT\n",
    "    if s==1: #profile code for 1 subj\n",
    "        %lprun -s -f STRUCT -T SpeedStrut.txt STRUCT(Xtrain,ytrain,Xtarget,ytarget,n_trees=10,C=Nclasses,verbos = True) \n",
    "      \n",
    "    STRUT_RF = STRUCT(Xtrain,ytrain,Xtarget,ytarget,n_trees=10,C=Nclasses,verbos = True)\n",
    "\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    ypred = np.asarray(map(lambda x:forest_classify_ensemble(STRUT_RF,x),Xtest))\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "\n",
    "    STRUTacc[k] = acc_c/Nclasses\n",
    "    print 'Accuracy w STRUT = %s\\n'%STRUTacc[k]\n",
    "    k = k+1\n",
    "\n",
    "print 'mean Acc - Source only = %s'%SOacc.mean()\n",
    "print 'mean Acc w STRUT = %s'%STRUTacc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   2.  -1.   4.  -1.   6.  -1.  -1.   9.  10.  11.  -1.  -1.  14.  -1.\n",
      "  -1.  17.  -1.  -1.]\n",
      "[  8.   3.  -1.   5.  -1.   7.  -1.  -1.  16.  13.  12.  -1.  -1.  15.  -1.\n",
      "  -1.  18.  -1.  -1.]\n"
     ]
    }
   ],
   "source": [
    "def TransferToSKLsequence(ch_left,ch_right,subset):\n",
    "    new_left = np.zeros(len(subset))\n",
    "    new_right = np.zeros(len(subset))\n",
    "    for i in range(len(subset)):\n",
    "        (I,) = np.where(subset == ch_left[subset[i]])\n",
    "        if len(I)==0:\n",
    "            new_left[i] = -1\n",
    "        else:\n",
    "            \n",
    "            new_left[i] = I\n",
    "            \n",
    "        (I,) = np.where(subset == ch_right[subset[i]])\n",
    "        if len(I)==0:\n",
    "            new_right[i] = -1\n",
    "        else:\n",
    "            new_right[i] = I\n",
    "    return (new_left,new_right)\n",
    "\n",
    "ch_left = np.array([ 1,  2,  3, -1,  5, -1, -1,  8,  9, -1, -1, 12, -1, -1, 15, 16, 17, -1, -1, 20, -1, -1, 23, 24, -1, -1, 27, -1, -1])\n",
    "ch_right = np.array([14, 7, 4, -1,  6, -1, -1, 11, 10, -1, -1, 13, -1, -1, 22, 19, 18, -1, -1, 21, -1, -1, 26, 25, -1, -1, 28, -1, -1])\n",
    "subset = np.array([ 0,  1,  2,  7,  8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26])\n",
    "(a,b) = TransferToSKLsequence(ch_left,ch_right,subset)\n",
    "print a\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[False False  True False False False False False False False False False\n",
      " False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "ch_left = np.array([ 1,  2,  3, -1,  5, -1, -1,  8,  9, -1, -1, 12, -1, -1, 15, 16, 17, -1, -1, 20, -1, -1, 23, 24, -1, -1, 27, -1, -1])\n",
    "ch_right = np.array([14, 7, 4, -1,  6, -1, -1, 11, 10, -1, -1, 13, -1, -1, 22, 19, 18, -1, -1, 21, -1, -1, 26, 25, -1, -1, 28, -1, -1])\n",
    "subset = np.array([ 0,  1,  2,  7,  8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26])\n",
    "print ch_left[subset[1]]\n",
    "I = (subset == ch_left[subset[1]])\n",
    "print I\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train a forest on Target data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, BAcc = 0.804935944011\n",
      "Patient 2, BAcc = 0.556784549917\n",
      "Patient 5, BAcc = 0.653978658868\n",
      "Patient 6, BAcc = 0.554037603531\n",
      "Patient 8, BAcc = 0.534470168882\n",
      "Patient 11, BAcc = 0.498515569636\n",
      "Patient 14, BAcc = 0.565454908539\n",
      "Patient 15, BAcc = 0.581813263402\n",
      "Patient 16, BAcc = 0.558014499038\n",
      "Patient 19, BAcc = 0.706019324856\n",
      "\n",
      "mean acc Target only = 0.601402449068\n"
     ]
    }
   ],
   "source": [
    "TOacc = np.zeros(len(PatientCodes)) \n",
    "Ntarget = np.zeros(len(PatientCodes))\n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 1)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 1)]\n",
    "    Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    Ntarget[k] = len(ytarget)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50)\n",
    "    RF = RF.fit(Xtarget,ytarget)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    TOacc[k] = BAcc\n",
    "    print 'Patient %s, BAcc = %s'%(s,TOacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print '\\nmean acc Target only = %s'%TOacc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEZCAYAAABrUHmEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOI4TG1cajuM4Tmz+H6ZCNeBe4NySAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x138db7310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1)\n",
    "plt.subplot(221)\n",
    "plt.plot(SERacc-TOacc,'ro-')\n",
    "plt.xlabel('Patient #')\n",
    "plt.ylabel('Balanced Accuracy')\n",
    "plt.title('(SER - Target_only)')\n",
    "\n",
    "plt.subplot(223)\n",
    "plt.plot(SERacc,'ro-',TOacc,'bo-')\n",
    "plt.xlabel('Patient #')\n",
    "plt.ylabel('Balanced Accuracy')\n",
    "#plt.legend(['w SER','Target only'])\n",
    "\n",
    "plt.subplot(222)\n",
    "plt.plot(Ntarget)\n",
    "plt.title('target samples per subject')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SER can boost accuracy in some cases, while for others it is outperformed by a model trained on the target data only. Also, the target session matters (e.g. using session 4 as the target drastically decreases the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.78083249],\n",
       "       [ 0.78083249,  1.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(SERacc,Ntarget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Need to add a confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train on Source (Healthy) + Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, BAcc = 0.734037168364\n",
      "Patient 2, BAcc = 0.423518372406\n",
      "Patient 5, BAcc = 0.528363990575\n",
      "Patient 6, BAcc = 0.619051650027\n",
      "Patient 8, BAcc = 0.518096439157\n",
      "Patient 11, BAcc = 0.550120727058\n",
      "Patient 14, BAcc = 0.552199311132\n",
      "Patient 15, BAcc = 0.535050986683\n",
      "Patient 16, BAcc = 0.676307113305\n",
      "Patient 19, BAcc = 0.50103847815\n",
      "Mean BAcc using Source + Target = 0.563778423686\n"
     ]
    }
   ],
   "source": [
    "XHealthy = HealthyData.select_columns(feature_cols).to_numpy()\n",
    "yHealthy = HealthyData.select_columns(label_cols).to_numpy()\n",
    "yHealthy = yHealthy.reshape(-1) #to squeeze last dimension and obtain a 1D array\n",
    "SaTacc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 1)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 1)]\n",
    "    Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "\n",
    "    Xtrain = np.concatenate((XHealthy,Xtarget),axis=0)\n",
    "    ytrain = np.concatenate((yHealthy,ytarget),axis=0)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    SaTacc[k] = BAcc\n",
    "    print 'Patient %s, BAcc = %s'%(s,SaTacc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc using Source + Target = %s'%SaTacc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.47027668  0.80493594  0.73403717  0.65589653]\n",
      " [ 0.34356476  0.55678455  0.42351837  0.36069061]\n",
      " [ 0.46302359  0.65397866  0.52836399  0.51038908]\n",
      " [ 0.58641984  0.5540376   0.61905165  0.86269511]\n",
      " [ 0.3006138   0.53447017  0.51809644  0.65068006]\n",
      " [ 0.52889891  0.49851557  0.55012073  0.88847613]\n",
      " [ 0.49995839  0.56545491  0.55219931  0.85183507]\n",
      " [ 0.44732281  0.58181326  0.53505099  0.76520909]\n",
      " [ 0.66877704  0.5580145   0.67630711  0.72132396]\n",
      " [ 0.50256238  0.70601932  0.50103848  0.46540353]]\n"
     ]
    }
   ],
   "source": [
    "SOacc = np.expand_dims(SOacc, axis=1)\n",
    "TOacc = np.expand_dims(TOacc, axis=1)\n",
    "SaTacc = np.expand_dims(SaTacc, axis=1)\n",
    "SERacc = np.expand_dims(SERacc, axis=1)\n",
    "\n",
    "AccAll = np.concatenate((SOacc,TOacc,SaTacc,SERacc),axis=1)\n",
    "print AccAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEACAYAAABF+UbAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x135d97ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(AccAll)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Specificity paper tests\n",
    "* Note: Patients currently used are 1 2 5 6 8 11 14 15 16 19\n",
    "* Current paper draft: Sessions 1,2,3 CBR are used for testing, Session 4 CBR as target\n",
    "* **Impairment Specific**: is trained on all but one SCO and tested on the remaining CBR patient\n",
    "* **Patient Specific**: is trained on all SCO data (for that patient) and tested on Sessions 1,2,3 of CBR for the same patients\n",
    "* **Device-Specific**: trained using Leave One Session Out across sessions 1,2,3 of CBR data for that patient. That means the model is trained on Sessions 1,2 and tested on 3 (and then cycles through the combinations). Session 4 was left out for target data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PatientCodes = np.array([1, 2, 5, 6, 8, 11, 14, 15, 16, 19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impairment specific model (Leave one subject out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Impairment specific (SCO) model - BAcc = 0.543984111501\n",
      "Patient 2, Impairment specific (SCO) model - BAcc = 0.497768337469\n",
      "Patient 5, Impairment specific (SCO) model - BAcc = 0.488253786099\n",
      "Patient 6, Impairment specific (SCO) model - BAcc = 0.550538747842\n",
      "Patient 8, Impairment specific (SCO) model - BAcc = 0.46746662647\n",
      "Patient 11, Impairment specific (SCO) model - BAcc = 0.543220688805\n",
      "Patient 14, Impairment specific (SCO) model - BAcc = 0.58054560037\n",
      "Patient 15, Impairment specific (SCO) model - BAcc = 0.571897224455\n",
      "Patient 16, Impairment specific (SCO) model - BAcc = 0.544442163861\n",
      "Patient 19, Impairment specific (SCO) model - BAcc = 0.883598427716\n",
      "Mean BAcc - Impairment Specific (SCO) = 0.567171571459\n"
     ]
    }
   ],
   "source": [
    "ISpec_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)] #test on 3 CBR sessions\n",
    "    Nclasses = len(train['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    ISpec_acc[k] = BAcc\n",
    "    print 'Patient %s, Impairment specific (SCO) model - BAcc = %s'%(s,ISpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Impairment Specific (SCO) = %s'%ISpec_acc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on SCO and test on CBR (Patient Specific model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.690657930136\n",
      "Patient 2, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.514201316211\n",
      "Patient 5, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.641250439644\n",
      "Patient 6, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.539390667014\n",
      "Patient 8, Nclasses = 3, Personal model (Trained on SCO) - BAcc = 0.712432565372\n",
      "Patient 11, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.48350570923\n",
      "Patient 14, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.489253976453\n",
      "Patient 15, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.413609989896\n",
      "Patient 16, Nclasses = 5, Personal model (Trained on SCO) - BAcc = 0.489487962491\n",
      "Patient 19, Nclasses = 3, Personal model (Trained on SCO) - BAcc = 0.780840989076\n",
      "Mean BAcc - Patient Specific (SCO) = 0.575463154552\n"
     ]
    }
   ],
   "source": [
    "PSpec_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] == s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)]\n",
    "    Nclasses = len(test['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    #acc = sum(ypred == ytest)/len(ytest)\n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    \n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    PSpec_acc[k] = BAcc\n",
    "    print 'Patient %s, Nclasses = %s, Personal model (Trained on SCO) - BAcc = %s'%(s,Nclasses,PSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Patient Specific (SCO) = %s'%PSpec_acc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train and test on CBR - Device specific model (CBR)\n",
    "* Leave One Session Out of CBR \n",
    "* Keep out 1 session (#4) for target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, Device Specific model - BAcc = 0.803518022125\n",
      "Patient 2, Device Specific model - BAcc = 0.651113329939\n",
      "Patient 5, Device Specific model - BAcc = 0.629395231577\n",
      "Patient 6, Device Specific model - BAcc = 0.594012604338\n",
      "Patient 8, Device Specific model - BAcc = 0.881942741734\n",
      "Patient 11, Device Specific model - BAcc = 0.733450526503\n",
      "Patient 14, Device Specific model - BAcc = 0.84999289801\n",
      "Patient 15, Device Specific model - BAcc = 0.830651274766\n",
      "Patient 16, Device Specific model - BAcc = 0.661073852136\n",
      "Patient 19, Device Specific model - BAcc = 0.751907231714\n",
      "Mean BAcc - Device Specific (CBR) = 0.738705771284\n"
     ]
    }
   ],
   "source": [
    "DSpec_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    data =  CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)] #keep out 1 session for target\n",
    "    BAcc = 0\n",
    "    for session in range(1,4):\n",
    "                  \n",
    "        test = data[data['Session'] == session]\n",
    "        train = data[data['Session'] != session]\n",
    "    \n",
    "        Nclasses = len(target['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "        Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "        ytrain = train.select_columns(label_cols).to_numpy()\n",
    "        ytrain = ytrain.reshape(-1)\n",
    "        Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "        ytest = test.select_columns(label_cols).to_numpy()\n",
    "        ytest = ytest.reshape(-1)\n",
    "\n",
    "        RF = RandomForestClassifier(n_estimators=50)\n",
    "        RF = RF.fit(Xtrain,ytrain)\n",
    "        ypred = RF.predict(Xtest)\n",
    "        #acc = sum(ypred == ytest)/len(ytest)\n",
    "        #balanced accuracy\n",
    "        acc_c = 0\n",
    "        for c in np.unique(ytest):\n",
    "            i = ytest == c\n",
    "            correct = ypred[i] == ytest[i]\n",
    "            acc_c += sum(correct)/len(correct)\n",
    "\n",
    "        BAcc += acc_c/len(np.unique(ytest)) #for current session\n",
    "        \n",
    "    DSpec_acc[k] = BAcc/3 #the CV BAcc on 3 session \n",
    "    print 'Patient %s, Device Specific model - BAcc = %s'%(s,DSpec_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Device Specific (CBR) = %s'%DSpec_acc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can we boost an impairment-specific model with the Device data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1, BAcc Impairment specific only = 0.57835963364, Bacc w SER = 0.595887038601\n",
      "Patient 2, BAcc Impairment specific only = 0.496082636568, Bacc w SER = 0.501462995569\n",
      "Patient 5, BAcc Impairment specific only = 0.482115943604, Bacc w SER = 0.498647282775\n",
      "Patient 6, BAcc Impairment specific only = 0.563228464701, Bacc w SER = 0.612659708275\n",
      "Patient 8, BAcc Impairment specific only = 0.46743938817, Bacc w SER = 0.752075664297\n",
      "Patient 11, BAcc Impairment specific only = 0.545551923753, Bacc w SER = 0.559630930743\n",
      "Patient 14, BAcc Impairment specific only = 0.616396651843, Bacc w SER = 0.616396651843\n",
      "Patient 15, BAcc Impairment specific only = 0.588985299386, Bacc w SER = 0.617322711911\n",
      "Patient 16, BAcc Impairment specific only = 0.532580984444, Bacc w SER = 0.540313477055\n",
      "Patient 19, BAcc Impairment specific only = 0.891267425385, Bacc w SER = 0.891267425385\n",
      "Mean BAcc - Impairment Specific only = 0.576200835149\n",
      "Mean BAcc - Impairment Specific w SER = 0.618566388645\n"
     ]
    }
   ],
   "source": [
    "ISpecSER_acc = np.zeros(len(PatientCodes)) \n",
    "ISpecSO_acc = np.zeros(len(PatientCodes)) \n",
    "k = 0\n",
    "for s in PatientCodes:\n",
    "    \n",
    "    train = SCOData[(SCOData['SubjID'] != s)]\n",
    "    test = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] != 4)] #test on 3 CBR sessions\n",
    "    target = CBRData[(CBRData['SubjID'] == s) & (CBRData['Session'] == 4)] \n",
    "\n",
    "    Nclasses = len(train['Label'].unique()) #How many activities we have for this patient\n",
    "\n",
    "    Xtrain = train.select_columns(feature_cols).to_numpy()\n",
    "    ytrain = train.select_columns(label_cols).to_numpy()\n",
    "    ytrain = ytrain.reshape(-1)\n",
    "    Xtarget = target.select_columns(feature_cols).to_numpy()\n",
    "    ytarget = target.select_columns(label_cols).to_numpy()\n",
    "    ytarget = ytarget.reshape(-1)\n",
    "    Xtest = test.select_columns(feature_cols).to_numpy()\n",
    "    ytest = test.select_columns(label_cols).to_numpy()\n",
    "    ytest = ytest.reshape(-1)\n",
    "    \n",
    "    RF = RandomForestClassifier(n_estimators=50)\n",
    "    RF = RF.fit(Xtrain,ytrain)\n",
    "    ypred = RF.predict(Xtest)\n",
    "    \n",
    "    #balanced accuracy - Source only\n",
    "    acc_c = 0\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)    \n",
    "    ISpecSO_acc[k] = acc_c/len(np.unique(ytest))\n",
    "    \n",
    "    #combining source w target data\n",
    "    newRF = SERfuncs.forest_convert(RF)\n",
    "    expRF = SERfuncs.forest_SER(newRF,Xtarget,ytarget,C=Nclasses) #refine RF on current data (C is the # of classes on the source)\n",
    "      \n",
    "    #balanced accuracy\n",
    "    acc_c = 0\n",
    "    ypred = np.asarray(map(lambda x:SERfuncs.forest_classify_ensemble(expRF,x),Xtest))\n",
    "    for c in np.unique(ytest):\n",
    "        i = ytest == c\n",
    "        correct = ypred[i] == ytest[i]\n",
    "        acc_c += sum(correct)/len(correct)\n",
    "    BAcc = acc_c/len(np.unique(ytest))\n",
    "    ISpecSER_acc[k] = BAcc\n",
    "        \n",
    "    print 'Patient %s, BAcc Impairment specific only = %s, Bacc w SER = %s'%(s,ISpecSO_acc[k],ISpecSER_acc[k])\n",
    "    k = k+1\n",
    "\n",
    "print 'Mean BAcc - Impairment Specific only = %s'%ISpecSO_acc.mean()    \n",
    "print 'Mean BAcc - Impairment Specific w SER = %s'%ISpecSER_acc.mean()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No significant boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12dd86c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(Xtrain)\n",
    "plt.show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
